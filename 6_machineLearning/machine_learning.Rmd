---
title: "Aprendizaje automático (Machine Learning)"
output: html_document
date: '2022-05-05'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Antes de empezar...
```{r install}
#install.packages(c("tidymodels", "vip", "mlbench", "rpart.plot"))
```


## Aprendizaje automático (Machine Learning)
El aprendizaje automático (Machine Learning) es una rama de la inteligencia 
artificial basada en la creación de modelos computacionales capaces de aprender 
de los datos, identificar patrones y tomar decisiones con una mínima intervención
humana. Los modelos de aprendizaje automáticos pueden llegar a ser muy complejos, 
lo que hace que no siempre sean fácilmente interpretables (aunque existen
excepciones, tal y como veremos).

Aunque los modelos de aprendizaje automático pueden resolver muchos tipos de 
tareas, nos centraremos en:

* Regresión: Predicción de una magnitud continua. Por ejemplo: ¿qué temperatura hará mañana?
* Clasificación: Predicción de categorías (clases). Por ejemplo, ¿qué enfermedad
sufre el paciente: gripe, covid, o ninguna?"


## Ejemplo: los peligros del aprendizaje automático
Los modelos lineales construidos con `lm` pueden considerarse modelos (sencillos)
de aprendizaje automático. Para darles potencia, podemos emplear predictores 
(features) más complejos, como expresiones polinomiales. 

Usa `lm` para ajustar los datos de "lm_ml.csv".

```{r}
# tODO: borrar
x <- seq(-1, 1, len=20)
y <- cos(4* x + 4) + rnorm(length(x), sd = 0.4)
plot(x, y)
write.csv(data.frame(x=x, y=y), "data/lm_ml.csv", row.names = FALSE)
```
```{r}

plot_model = function(model, col = 1) {
  xxx = seq(-1, 1, len=500)
  lines(xxx, predict(model, data.frame(x = xxx)), col = col, lwd=2)
}


df = read.csv("data/lm_ml.csv")
lmf1 = lm(y ~ x, data = df)
lmf2 = lm(y ~ poly(x, 5), data = df)
lmf3 = lm(y ~ poly(x, 19), data = df)



plot(x, y, ylim=c(-5, 5))
plot_model(lmf1)
plot_model(lmf2, col=2)
plot_model(lmf3, col=3)
lines(x, cos(4 * x + 4), col = 4)
legend("bottomright", c("underfit", "niceee", "overfit", "ground truth"),
       col=1:4, lwd=2)

```
```{r wrong_evaluation}
evaluate_model = function(model) { 
  yardstick::rmse_vec(truth = y, estimate = predict(model))
}

print(paste("Model 1 has error: ", evaluate_model(lmf1)))
print(paste("Model 2 has error: ", evaluate_model(lmf2)))
print(paste("Model 3 has error: ", evaluate_model(lmf3)))
```
```{r better_evaluation}
evaluate_model = function(model) { 
  eval_points = seq(-1, 1, len=100)
  yardstick::rmse_vec(
    truth = cos(4 * eval_points + 4), 
    estimate = predict(model, data.frame(x=eval_points))
  )
}

print(paste("Model 1 has error: ", evaluate_model(lmf1)))
print(paste("Model 2 has error: ", evaluate_model(lmf2)))
print(paste("Model 3 has error: ", evaluate_model(lmf3)))
```
Moraleja: El rendimiento de un modelo requiere de una **métrica** y debe 
**evaluarse fuera del conjunto de entrenamiento**. Esto nos llevará a hablar 
de conjuntos de **entrenamiento** y **test**.

En las siguientes secciones, haremos uso de la librería `tidymodels` para 
crear y evaluar modelos de aprendizaje automático. Existen otras librerías
fantásticas como `caret` y `mlr3` (o su antecesora `mlr`) que puedes probar.

```{r loading_tidymodels}
library('tidymodels')
```

## Árboles de decisión.
Los Árboles de decisión son una buena elección si deseas construir un modelo 
de aprendizaje automático interpretable.

### Ejemplo: clasificación de animales
El dataset `Zoo` contiene 101 casos y 17 variables de observaciones 
realizadas en varios animales; 16 de estas variables son lógicas, indicando la
presencia o ausencia de alguna característica, y la variable `type` es un facto
r que contiene las clases de animales que deseamos predecir.

```{r load_zoo}
data(Zoo, package = "mlbench")
zoo = Zoo %>% as_tibble %>% mutate_if(is.logical, as.factor)
```


```{r decision_tree}
# 1) Creación de un árbol de decisión
tree_spec <- decision_tree(tree_depth = 3) %>%
  set_engine("rpart") %>%
  set_mode("classification")

# 2) El árbol aprende a partir de los datos
fitted_tree = fit(tree_spec, type ~ ., data = zoo)
```

```{r decision_tree_visualization}
# 3) Podemos visualizar la toma de decisiones del árbol. 
library("rpart.plot")
# xtract_fit_engine()
rpart.plot(fitted_tree$fit, roundint = FALSE,
           box.palette = "BuBn",
           type = 5)
```

```{r}
# 4) También es posible visualizar qué características son las más relevantes 
# a la hora de predecir la clase... ¡Esto nos permite aprender del modelo!
library("vip")

fitted_tree %>%
  vip(geom = "col", aesthetics = list(fill = "midnightblue", alpha = 0.8)) +
  scale_y_continuous(expand = c(0, 0))
```

Aunque las decisiones del árbol parecen razonables es buena práctica evaluar
el rendimiento del modelo. Para ello seguiremos las lecciones aprendidas
con el ejemplo de regresión debemos:

* Elegir una métrica: emplearemos `accuracy`, la proporción de predicciones correctas.
* Dividir el conjunto de datos en entrenamiento y test.

```{r split_for_model_evaluation}
set.seed(123)
zoo_split = initial_split(zoo, strata = type)
zoo_train = training(zoo_split)
zoo_test = testing(zoo_split)
```

## Ejercicio: Rendimiento del sistema
Usa los conjuntos de entrenamiento y test para obtener el rendimiento del 
árbol de decisión. Sigue los pasos indicados en los comentarios:

```{r}
# 1) Repite el entrenamiento, pero esta vez usa el conjunto de entrenamiento
fitted_tree = fit(tree_spec, type ~ ., data = zoo_train)
# 2) Usa predict() para obtener predicciones sobre el conjunto de test. Guarda
# las predicciones en la variable preds
preds = predict(fitted_tree, zoo_test)
# 3) Calcula el porcentaje de predicciones correctas comparando la clase real 
# (zoo_test$type) con preds. Puedes usar las funciones accuracy (o accuracy_vec)
acc = accuracy_vec(truth = zoo_test$type, estimate = preds$.pred_class)
print(acc)
```


# Ejemplo: Rendimiento del sistema mediante Bootstrap
Podemos obtener una mejor estimación del `accuracy` del sistema repitiendo 
varias veces el procedimiento anterior y luego promediando los resultados 
(¡y además podemos obtener una estimación del error!). Aunque existen varios
procedimientos para realizar esta repetición, el más sencillo de entender
quizás sea Monte Carlo Cross-validation (validación cruzada de Monte Carlo):

```{r}
folds = mc_cv(zoo, times = 10, prop = 9 / 10)
performance = tree_spec %>% fit_resamples(type ~ ., resamples = folds,
                                          metrics=metric_set(accuracy))

collect_metrics(performance)
```


# Ejemplo: Elección de hiperparámetros
En la construcción del modelo especificamos a mano el **hiperparámetro** 
`tree_depth = 3`. Aunque se puede intentar elegir a mano (¡ojo porque esto
puede llevar a overfitting!), lo mejor es automatizar el proceso

```{r tuning}
tree_spec = decision_tree(
  tree_depth = tune(),
  cost_complexity = tune()
) %>%
  set_engine("rpart") %>%
  set_mode("classification")

tree_grid = grid_regular(cost_complexity(),
                         tree_depth(),
                         levels = 3)
tree_grid


tree_res =  tree_spec %>% 
  tune_grid(
    type ~ .,
    resamples = folds,
    grid = tree_grid
  )
```
```{r}
collect_metrics(tree_res)
autoplot(tree_res)

show_best(tree_res, "accuracy")
select_best(tree_res, "accuracy")

final_tree = finalize_model(tree_spec, select_best(tree_res, "accuracy"))
final_fit <- fit(final_tree, type ~ ., zoo_train)
```

### Ejercicio: regresión con el dataset Boston
El conjunto de datos `Boston` contiene varias estadísticas para 506 vecindarios 
de Boston. Construye un modelo de regresión que prediga el valor medio de las
viviendas ocupadas por sus propietarios (`medv`). (Nota: el conjunto de datos 
`Boston` es bastante antiguo y contiene algunas variables realmente desafortunadas.)

```{r}
data("Boston", package = "MASS")
Boston = as_tibble(Boston)
```



#https://rstudio-pubs-static.s3.amazonaws.com/802290_cb734d1218864fd093bdcf69208bd21a.html
