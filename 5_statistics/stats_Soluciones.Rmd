---
title: "Análisis estadístico"
output: html_document
author: Constantino A. García (constantino.garciama@ceu.es)
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Antes de empezar...
Instala las librerías necesarias (copia y pega en la terminal; no descomentes
la línea)...

```{r}
# install.packages(
#  c("tidyverse", "afex", "emmeans", "GGally", "effectsize", "performance", "see", "qqplotr")
# )
```

... y carga las librerías más usadas: 

```{r, echo=FALSE}
library("tidyverse")
theme_set(theme_bw())  # cambia el tema de ggplot
```

El modelado estadístico es difícil, por lo que en este notebook solo 
cubriremos algunos aspectos básicos. Si en el futuro te enfrentas a experimentos
complejos, considera buscar ayuda.

>To consult the statistician after an experiment is finished is often merely to 
ask him to conduct a post mortem examination. He can perhaps say what the 
experiment died of. (Ronald Fisher)


## Modelado estadístico: las dos culturas
En el artículo clásico [Statistical modeling: The two cultures]((https://projecteuclid.org/journals/statistical-science/volume-16/issue-3/Statistical-Modeling--The-Two-Cultures-with-comments-and-a/10.1214/ss/1009213726.full)) encontramos 

> There are two cultures in the use of statistical modeling to reach conclusions from
data. One assumes that the data are generated by a given stochastic data model. The
other uses algorithmic models and treats the data mechanism as unknown. (Leo Breiman)

* *Explanatory modeling*: modelos estadísticos empleados para probar una teoría (causal?).
Para ello se emplean variables con un significado científico claro y se evalúa si tienen 
una relación *significativa* con la variable de interés. $\rightarrow$ "Estadística clásica"
basada en **modelos lineales**.
* *Predictive modeling*: modelos cuyo propósito es predecir observaciones nuevas 
o futuras. $\rightarrow$ **Aprendizaje automático** (*machine learning*).

En este notebooks nos centraremos en modelos lineales y en los métodos de inferencia
clásica. El siguiente notebook cubre modelos basados en aprendizaje automático.

(Otras lecturas interesante sobre las dos culturas es [To explain or to predict?](https://www.stat.berkeley.edu/~aldous/157/Papers/shmueli.pdf).)

# Regression is all you need
## Regresión simple

El modelo básico sobre el que se construye gran parte de la "Estadística clásica"
es el modelo de **regresión lineal**:
$$y = a + b\cdot x + \epsilon$$
donde $\epsilon \sim \mathcal{N}(0, \sigma^2)$.

Es instructivo simular datos que sigan este modelo para entender el significado
de la ecuación:

```{r}
x = seq(-2, 2, 0.1)
expected_behaviour = 2 + 3 * x  # a = 2 y b = 3
epsilon = rnorm(length(x), sd = 1)
y = expected_behaviour + epsilon

df = data.frame('data_x' = x, 'data_y' = y, 
                'expected' = expected_behaviour)
ggplot(df, aes(x = data_x)) + 
  geom_point(aes(x = data_x, y = data_y)) + 
  geom_line(aes(y = expected), col = 2)

# OR...
# plot(x, y)
# lines(x, expected_behaviour, col = 2)
```

Podemos pensar que `expected_behaviour` ($a + b\cdot x$) es el comportamiento
medio o esperado en la población de interés, mientras que `epsilon` ($\epsilon$)
representan fluctuaciones aleatorias (bien debidas a errores del proceso de
medición o que el proceso  estudiado tiene cierta aleatoriedad). Además, la 
relación entre $x$ e $y$ es muy específica. Si aumenta (disminuye) $x$ aumenta
(disminuye) $y$. Además, un  incremento de una unidad en $x$ siempre produce el 
mismo incremento en $y$ (ídem si $x$ disminuye). Se dice que la relación entre 
$x$ e $y$ es **lineal**.

La primera pregunta a la que nos enfrentamos es la siguiente. 
**Dados los datos $(x, y)$, ¿podemos estimar `expected behaviour`?**

![](https://media.giphy.com/media/l0ErOholJjSmFlMFG/giphy.gif)

### Ejemplo: linear model (lm)
```{r}
# 1) crear un modelo lineal
naive_model = lm(data_y ~ data_x, data = df)
# 2) obtener estimaciones de a y b
summary(naive_model)
# 3) Obtener predicciones del modelo lineal
preds = predict(naive_model, interval = "confidence")
# 4) visualizar el ajuste
data_and_preds = df %>% bind_cols(preds)
ggplot(data_and_preds, aes(x = data_x)) + 
  geom_point(aes(y = data_y)) + 
  geom_line(aes(y = expected, col = "Expected")) + 
  geom_line(aes(y = fit, col = "Predicted")) + 
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.2, fill = "black")
```

Dado que las estimaciones incorporan el error de estimación, es posible realizar
inferencia acerca de la **significación** de los parámetros.

### Ejemplo: inferencia con lm
Un estudiante de biología desea determinar la relación entre
temperatura ambiente y frecuencia cardíaca en la rana leopardo, *Rana pipiens*.
Para ello, manipula la temperatura en incrementos de 2ºC que van desde
2ºC a 18ºC, registrando la frecuencia cardíaca (pulsaciones por minuto) en cada
intervalo. Los datos están disponibles en "hr.csv".

```{r}
# 1) leer los datos
frog_df = read.table("data/hr.csv", header = TRUE)
# 2) Crear un modelo lineal
frog_model = lm(heart_rate ~ temperature, data = frog_df)
# 3) Inferencia
summary(frog_model)
```

---

El diseño experimental y los resultados de la inferencia en el ejemplo de las ranas
nos invitan a concluirque "el aumento de la temperatura *causa* un incremento de 
la frecuencia cardíaca". Sin embargo, esto no es correcto. Por muy fuerte que 
parezca la relación entre las variables $x$ e $y$, **nunca debemos interpretar 
una variable como la causa de la otra**. Una relación significativa entre $x$ e 
$y$ puede ocurrir por varios motivos:

1. $x$ causa $y$.
2. $y$ causa $x$.
3. Existe un tercer factor (llamado **variable de confusión**) que, bien directa
o indirectamente, causa $x$ e $y$.

![](https://qph.fs.quoracdn.net/main-qimg-13d22f6fda3811a9108d18b71c46e933-pjlq)

Por otra parte, respecto a los **p-valores**...

> There is some debate among statisticians and researchers about the appropriateness 
of P values, and that the term "statistical significance" can be misleading. If you 
have a small P value, it only means that the effect being tested is unlikely to be
explained by chance variation alone, in the context of the current study and the 
current statistical model underlying the test. If you have a large P value, it 
only means that the observed effect could plausibly be due to chance alone: it
is wrong to conclude that there is no effect (emmeans package authors)

En general, hay consenso en que 
**debe abandonarse la interpretación dicotómica  del p-valor** 
(efecto significativo Vs no-significativo, sobre todo teniendo en 
cuenta que se basan en un threshold arbitrario) y 
**que debe favorecerse los resultados basados en intervalos de confianza y tamaños de los efectos**
(¡incluso si no son significativos!)

> For example, a study on the effects of two different ambient temperatures on 
paramecium diameter returning an effect size of 20 µm and a p-value of 0.1, 
if centred on p-value interpretation would conclude 'no effect' of temperature,
despite the best supported effect size being 20, not 0. An interpretation based on effect size and confidence intervals could, for example, state: 'Our results suggest that 
paramecium kept at the lower temperature will be on average 20 µm larger in size, 
however a difference in size ranging between −4 and 50 µm is also reasonably likely'. 
(...), the latter approach acknowledges the uncertainty in the estimated effect 
size while also ensuring that you do not make a false claim either of no effect
if p > 0.05, or an overly confident claim. (Lewis G. Halsey, [The reign of p-value is over](https://royalsocietypublishing.org/doi/10.1098/rsbl.2019.0174))

### Ejemplo: intervalos de confianza en lm
```{r}
summary(frog_model)
confint(frog_model)
```
Los resultados sugieren que el ritmo cardiaco de las ranas se incrementará
1.77 bpms por cada grado Celsius, si bien un aumento de la frecuencia 
cardiaca en el rango (1.37, 2.17) es igualmente verosímil.

### Validación de los modelos
Evidentemente cualquier interpretación está supeditada a que el modelo sea 
correcto. Debemos ser muy cuidadosos a la hora de verificar que se cumplan las
asunciones del modelo de regresión lineal. Podemos usar el acrónimo **LINE** para
recordar las asunciones más importantes del modelo: 
**Linear, Independent, Normal, Equal variances**.

### Ejemplo: evaluación del modelo `naive_model`
```{r}
plot(naive_model, ask = FALSE)

# Comprobar la normalidad con qqplot puede ser difícil. Podemos apoyarnos en 
# performance::check_normality 
library("performance")
# check_normality corre shapiro.test, pero tal y como resalta la documentación
# "this formal test almost always yields significant results for the distribution
# of residuals and visual inspection (e.g. Q-Q plots) are preferable."
is_norm = check_normality(naive_model)

# Para hacer la inspección visual
plot(is_norm)
plot(is_norm, type = "qq")
plot(is_norm, type = "qq", detrend=TRUE)
```

### Ejercicio: predicción de AT abdominal
Després et al. [^1] señalan que el tejido adiposo (AT) se asocia con complicaciones
metabólicas consideradas como factores de riesgo para la enfermedad 
cardiovascular. Es importante, afirman, medir la cantidad de AT intraabdominal
como parte de la evaluación del riesgo de enfermedad cardiovascular de un 
individuo. Després y sus colegas realizaron un estudio para predecir la 
cantidad de AT abdominal a partir de simples mediciones antropométricas. 

Entre las medidas tomadas en cada sujeto, se incluyó la AT abdominal obtenida por
TC y la circunferencia de la cintura (datos en Wat.csv''). Una pregunta de 
interés es cómo de bien se puede predecir y estimar la AT abdominal a partir del 
conocimiento de la circunferencia de la cintura. Construye un modelo lineal y
plotea sus predicciones. ¿Existe alguna relación entre AT y la circunferencia
de la cintura?

[^1]: J. Després, D. Homme, M. Pouliot, A. Tremblay,
and C. Bouchard, ``Estimation of Deep Abdominal Adipose-Tissue Accumulation 
from Simple Anthropometric Measurements in Men'' American Journal of Clinical
Nutrition, 54 (1991), 471–477.

```{r}
at_df = read.table("data/at.csv", header=TRUE, sep = ",") 
names(at_df) = c("subject", "waist", "AT")
at_model = lm(AT ~ waist, data = at_df)
at_with_preds = 
  at_df %>% 
  mutate(fit = predict(at_model))


confint(at_model)

ggplot(at_with_preds, aes(x = waist, y = AT)) + 
  geom_point() + 
  geom_line(aes(y = fit, col = "Predictions")) + 
  xlab("waist circumference (cm)") + 
  ylab("deep abdominal AT (cm2)")

```

### Ejercicio: asunciones en el problema de AT abdominal
¿Se cumplan las asunciones de la regresión lineal en el problema de AT abdominal?

```{r}
plot(at_model, ask = FALSE)
# No, el ruido es heterocedastico (no es el mismo para todos los valores):
# ver plot 3.
```

## Regresión múltiple
Para lidiar con situaciones como la ilustrada en el gráfico de 
"correlation is not causation" (tiburones Vs helados)
necesitamos emplear modelos de **regresión múltiple**, dado que estos permiten 
"controlar" las variables de confusión. Crear un modelo de regresión múltiple
es análogo al caso unidimensional...

### Ejemplo: regresión múltiple
Jansen y Keller[^2] utilizaron la edad y el nivel de educación para predecir la
capacidad de dirigir la atención (CDA) en sujetos ancianos. CDA se refiere a
los mecanismos neuronales que enfocan la mente en lo que es significativo al
tiempo que bloquea las distracciones. El estudio recopiló información sobre 71
mujeres mayores con estado mental normal. En este estudio las puntuaciones
más altas se corresponden con un mejor funcionamiento de la atención. Las
mediciones en CDA, edad en años y el nivel de educación (años de escolaridad)
están recogidos en “cda.csv”. Crea un modelo de regresión múltiple para predecir la
puntuación de CDA.

[^2] D. Jansen, M. Keller, Çognitive Function in Community-Dwelling Elderly Women”, Journal of
Gerontological Nursing, 29 (2003), 34-43.

```{r}
library("GGally")

df = read.csv("data/cda.csv")
ggpairs(df)
cda_model = lm(CDA ~ AGE + EDLEVEL, df)
# cda_model = lm(CDA ~ ., df)  # equivalente al comando anterior
df$predictions = predict(cda_model)

summary(cda_model)
```

### Ejercicio: asunciones del modelo de CDA
```{r}
plot(cda_model, ask=FALSE)
# todo parece correcto!
```

---

Hasta ahora solo hemos usado datos continuos, pero nada evita usar datos categóricos
como predictores. ¡Ojo! Los coeficientes asociados a datos categóricos no deben 
interpretarse como una pendiente.

### Ejemplo: regresión múltiple con datos categóricos
Construye un modelo de regresión lineal para predecir el peso de una persona a partir
de los datos contenidos en "antrop.csv". Interpreta los coeficientes de la regresión.

```{r}
antrop = read.csv("data/antrop.csv")
antrop = mutate(antrop, male = factor(male))
antrop_model = lm(weight ~ height + male, data = antrop)
summary(antrop_model)

antrop_preds = antrop %>% mutate(fit = predict(antrop_model))
ggplot(antrop_preds, aes(x = height, col=male)) + 
  geom_point(aes(y = weight)) + 
  geom_line(aes(y = fit), lwd = 3)

summary(antrop_model)
```

El modelo se puede escribir como
$$weight = -29 + 0.47 * height + 1.23 * is-male$$ 
por lo que 1.23 significa que, de media y para una misma altura, los hombres 
pesan 1.23 Kg más que las mujeres (hemos **ajustado por el efecto de la altura**).

### Ejercicio: Intervalos de confianza
Usa intervalos de confianza para interpretar los resultados de la regresión.

```{r}
confint(antrop_model)
```

Aunque es cierto que de media los hombres pesan 1.23 Kg que las mujeres, ¡no 
podemos descartar que las mujeres pesen más que los hombres! (hasta 0.22 Kg).

### Ejercicio: Howell
Los datos contenidos en "howell1.csv" son datos censales parciales del 
área !Kung San compilados a partir de entrevistas realizadas a finales de la década
de 1960. Crea un modelo para predecir el peso de los individuos a partir 
de la altura y el sexo. Evalúa la bondad del modelo.

```{r}
howell = read.csv("data/howell1.csv", sep = ";")
howell = mutate(howell, male = factor(male))
howell_model = lm(weight ~ height + male, data = howell)
summary(howell_model)

howell_preds = howell %>% mutate(fit = predict(howell_model))
ggplot(howell_preds, aes(x = height, col=male)) + 
  geom_point(aes(y = weight)) + 
  geom_line(aes(y = fit), lwd = 3)
```

Sin ni siquiera usar `plot(howell_model)` ya somos capaces de ver que el ajuste
es malo... cualquier conclusión basada en un modelo erróneo será errónea 
(**garbage in, garbage out**).


### Ejemplo: dummy variables y contrastes
El dataset `iris` (puedes obtenerlo con `data(iris)`) contiene medidas del sépalo
y pétalo de varias especies de iris. Construye un modelo lineal para predecir
la longitud del sépalo únicamente en función de la especie. Interpreta los coeficientes
de la regresión.

```{r}
data(iris)
iris_model = lm(Sepal.Length ~ Species, iris)
print(summary(iris_model))

iris_preds = iris %>%  mutate(fit = predict(iris_model))
ggplot(iris_preds, aes(x=Species, fill = Species)) + 
  geom_boxplot(aes(y=Sepal.Length)) + 
  geom_point(aes(y = fit), shape=4, size=3)
```

Al interpretar los coeficientes de la regresión, observamos que 
`lm` ha tomado como referencia la especie `setosa`. Esto se puede observar usando
`contrasts`.

```{r}
contrasts(iris$Species)
```

Es decir el modelo es
$$sepal = mean-setosa-sepal + 0.93 * is-versicolor + 1.58 * is-virginica.$$

Sin embargo, podríamos reescribir el modelo de otra forma de forma 
que los coeficientes tengan otro significado. Un ejemplo sencillo sería:
$$sepal = mean-versicolor-sepal + \alpha_1 * is-setosa + \alpha_2 * is-virginica.$$

En este caso, simplimente estamos variando la especie de referencia. De hecho, 
`contrast` se puede modificar para usar como referencia otro nivel del factor:

### Ejemplo: contrastes
```{r}
contrasts(iris$Species) = cbind("_is_setosa" = c(1, 0, 0), 
                                "_is_virginica" = c(0, 0, 1))
iris_model_2 = lm(Sepal.Length ~ Species, iris)
print(summary(iris_model_2))
```

Lo interesante es que podemos 
**ajustar los contrastes de forma que respondan a nuestras preguntas científicas**. 
En general, estos contrastes deben ser **ortogonales**.

### Ejemplo: contrastes ortogonales
Imagínemonos el siguiente universo paralelo. En este universo paralelo solo 
existe la especie setosa. Una empresa de ingeniería genética te contrata para
crear nuevas especies con un sépalo más grande. Desarrollas un método conocido
como "Método V", que tiene dos variantes "V-I" y "V-II". Los experimentos con
estas variantes dan lugar a dos nuevas especies que llamas versicolor (V-I) y 
virginica (V-II). Te planteas dos preguntas científicas: 

1. ¿Es el método V capaz de crear especies con el sépalo más grande?
2. ¿Existe alguna diferencia entre V-I y V-II?

```{r}
levels(iris$Species)
contrasts(iris$Species)
# Usamos versicolor como referencia y lo comparemos con las especie V
# (no te preocupes por los denominadores y céntrate en los numeradores)
contrasts(iris$Species) = cbind(
  "V - setosa" = c(-2, 1, 1) / 3, 
  "I - II" = c(0, 1, -1) / 2
)
contrasts(iris$Species)
v_model = lm(Sepal.Length ~ Species, iris)
summary(v_model)
confint(v_model)
```

El método V parace producir sépalos más grandes. Por otra parte, V-II es mejor
que V-I.

---

LLegados a este punto, ¡ya hemos cubierto el 90% de los contenidos habituales 
de un curso de estadística habitual! Aunque parezca mentira, ya hemos hecho 
análisis tan complejos como

* Análisis de la varianza (anova): por ejemplo, en el problema del método V,
* Análisis de la covarianza (ancova): con el dataset `antrop.csv` o `howell`,
* ...

Desde una perspectiva moderna, 
**todos los análisis clásicos (T-test, anova, ancova) pueden considerarse como simples modelos de regresión**.
Esto demuestra el  poder unificador de esta perspectiva. En las siguientes secciones
revisaremos sin embargo estos modelos clásicos para afianzar la conexión con los
modelos de regresión y profundizar en algunas cosas que nos han quedado en el tintero.


# T-tests: comparación de dos grupos

### Ejemplo: Comparación de grupos mediante regresión
¿Depende la altura de los !Kung adultos del sexo del inviduo? Emplea los datos en 
"howell1.csv".

```{r}
howell = read.csv("data/howell1.csv", sep = ";")
howell = mutate(howell, male = factor(male))
  
adult_howell = 
  howell %>% filter(age >= 18) %>% 
  mutate(male = factor(male)) %>% 
  mutate(sex = fct_recode(male, "male" = "1", "female" = "0"))

height_model = lm(height ~ sex, data = adult_howell)

summary(height_model)
```

### Ejemplo: histogramas 
Apoya tus conclusiones dibujando el histograma de las alturas por sexo

```{r}
ggplot(adult_howell, aes(x = height, fill=sex)) + geom_density(alpha=0.2)
```

### Ejemplo: evaluación del modelo
¿Cumple el modelo las asunciones de la regresión lineal?

```{r}
hist(resid(height_model))
```

Lo cierto es que, aunque correcto, nuestra aproximación no es la habitual a la
hora de **comparar la media de dos poblaciones**. Si las poblaciones son normales
(o si podemos invocar el Teorema Central del Límite), podemos hacer uso del 
`t.test`.

### Ejemplo: T-test para comparación de medias

```{r}
t.test(height ~ sex, adult_howell)
```


### Ejemplo: T-test de una sola cola 
El fichero "hc.csv" contiene los datos de un experimento para verificar si 
una hormana de crecimiento funciona o no. ¿Existen diferencias significativas
entre el grupo de control y el de tratamiento?

![](https://media.giphy.com/media/3ornka9rAaKRA2Rkac/giphy.gif)

```{r}
library("effectsize")

hc = read.csv("data/hc.csv")
t.test(height_inc_cm ~ group, hc, alternative="less")
cohens_d(height_inc_cm ~ group, data = hc, alternative = "less")

# o bien...
height_test = t.test(
  hc %>% filter(group == "control") %>% pull(height_inc_cm),
  hc %>% filter(group == "treatment") %>% pull(height_inc_cm),
  alternative = "less"
) 
cohens_d(height_test) 
# ¡o bien podemos dejar que la librería elija el tamaño del efecto adecuado!
effectsize(height_test)
```

Siempre debemos considerar el **tamaño del efecto**, bien en base a nuestro 
conocimiento o bien usando los estadísticos adecuados como *Cohen's D*. Para
*Cohen's D* la heurística es:

* $|d| \approx 0.2$: efecto pequeño (despreciable).
* $|d| \approx 0.5$: efecto medio.
* $|d| \approx 0.8$: efecto grande.

### Ejercicio: T-test de una sola cola
En los datos de `adult_howell`, ¿podemos concluir que los hombres son más altos que las mujeres?
¿Cuál es el tamaño del efecto?

```{r}
t.test(height ~ sex, adult_howell, alternative="less")
cohens_d(height ~ sex, data = adult_howell, alternative = "less")
```

### Ejercicio: T-test apareado
John M. Morton et al. [^3] examinaron la función de la vesı́cula biliar antes y
después de la fundoplicatura, una cirugı́a para detener el reflujo. Los autores
midieron la funcionalidad de la vesı́cula biliar calculando la fracción de eyección
de la vesı́cula biliar (GBEF) antes y después de la fundoplicatura. El objetivo de
la fundoplicatura es aumentar la GBEF, que se mide como un porcentaje. ¿Hay
evidencia para concluir que la fundoplicatura aumenta el funcionamiento de la
GBEF? Datos en "gbef_long.txt" (o "gbef.txt", para un reto).

```{r}
# Los datos en gbef.txt no están en el formato adecuado para un análisis estadístico...
# ¡hay que luchar para ordenarlos de forma correcta!

gbef_df = read.table("data/gbef.txt")
gbef_df[3, ] = c("ID", "", 1:(ncol(gbef_df) - 2))
gbef_df = t(gbef_df)

gbef_df = as.data.frame(gbef_df[-(1:2), ]) %>% setNames(gbef_df[1, ])
gbef_df = 
  gbef_df %>% mutate(
  Preop = as.numeric(Preop), 
  Postop = as.numeric(Postop),
  ID = factor(ID)
)

gbef_df_long =
  gbef_df %>%
  pivot_longer(Preop:Postop, names_to="class",  values_to = "gbef")
```


```{r}
gbef_df_long = read.table("data/gbef_long.txt", header = TRUE)
gbef_df_long = 
  gbef_df_long %>% 
  arrange(ID)

head(gbef_df_long)

preop = gbef_df_long %>% filter(class == "Preop") %>% pull(gbef)
postop = gbef_df_long %>% filter(class == "Postop") %>% pull(gbef)

gbef_test = t.test(postop, preop, paired = TRUE, alternative = "greater")
print(gbef_test)
cohens_d(gbef_test)
```

### Ejercicio: evaluación del modelo de datos apareados
```{r}
diff = postop - preop
hist(diff)
```


# ANOVA: comparación de medias para múltiples grupos

ANOVA permite comparar más de dos grupos entre sí (¡como ya hicimos con iris!).
Asumiendo los peligros de dar recetas generales, en una primera aproximación 
podemos seguir los siguientes pasos:

1. Explorar y visualizar los datos.
2. Construir y/o elegir contrastes. ¡Ojo! Si quieres usar 
**sumas de cuadrados de tipo III (recomendado), estos contrastes deben ser ortogonales.**
3. Usar el modelo ANOVA y verificar sus asunciones. 
4. Calcula contrastes o realiza **test post-hoc**.

Fíjate que ya hemos cubierto casi todos los pasos en los ejemplos de regresión. 
Los pasos novedosos son:

* Antes de usar contrastes, usamos un **test omnibus (ANOVA)**. Siguiendo el 
ejemplo del "método V", un test omnibus simplemente respondería a "¿Hay diferencias
entre la longitud del sépalo entre las distintas especies? El problema de los 
tests omnibus es que, si existen diferencias, no nos dicen entre qué especies
hay diferencias.
* Para descubrir qué especies difieren entre sí podemos emplear: 1) contrastes 
o 2) **tests post-hoc**. En general, usaremos contrastes si tenemos hipótesis
específicas que deseamos comprobar, mientras que usaremos test post-hoc si 
no tenemos hipótesis específicas (y queremos descubrir cualquier patrón
interesante en los datos).


### Ejemplo: el "método V", otra vez.
Repitamos el análisis realizado para el método V, incorporando además los 
nuevos pasos.

```{r}
library("car")  # Anova
options(contrasts = c("contr.sum", "contr.poly"))
data("iris")

# 1) Visualizar
head(iris)
ggplot(iris, aes(x=Species, y = Sepal.Length, fill=Species)) + geom_boxplot() + 
  coord_flip()

# 2) Especificar contrastes si tenemos alguna hipótesis específica 
# (no te preocupes de los denominadores)
contrasts(iris$Species) =  cbind(
  "V - setosa" = c(-2, 1, 1) / 3,
  "I - II" = c(0, 1, -1) / 2
)

contrasts(iris$Species)
v_model = lm(Sepal.Length ~ Species, iris)

# 3) Correr ANOVA: test omnibus
v_model_aov = Anova(v_model, type = 3)
```

En el caso de modelos ANOVA, existen varios tamaños de efecto. Entre los mas conocidos
están eta-squared y omega-squared. Para complicar aún más las cosas, las heurísticas
para clasificar el tamaño como pequeño, mediano o largo son distintas que para Cohen's d.
En el caso que nos ocupa, para eta-squared o omega-squared tendríamos:

* Pequeño: $\approx0.01$.
* Mediano: $\approx 0.06$.
* grande: $\approx0.14$.

En general, consulta el siguiente [FAQ](https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/effectSize) para
consultar las heurísticas.

```{r}
eta_squared(v_model_aov)  # o effectsize(v_model_aov)
omega_squared(v_model_aov) # omega-squared se supone que está menos sesgado que eta_squared
```

Antes de seguir adelante deberíamos comprobar que se cumplan las asunciones de
ANOVA. Dejémoslo para otro ejemplo y sigamos adelante.

En el código anterior, ANOVA nos indica que alguna(s) de las especies tiene(n)
un sépalo distinto al de lasotras especies... ¡Sin embargo no nos dice cuáles 
son estas especies!

Para descubrirlo podemos usar contrastes ...

```{r}
# 4.a) 
summary(v_model)
confint(v_model)
```

... o usar tests post-hoc. La idea básica de los tests post-hoc es fácil de entender:
dado que sé que existe alguna diferencia entre las especies, voy a comparar todas
las especies entre sí. El problema es que esto dispara el error tipo I muy rápidamente, 
por lo que tenemos que ser más conservadores a la hora de aceptar una diferencia
como significativa. Esto lo logramos con distintos métodos de **ajuste de p-valores**.
Fíjate que el test omnibus sirve como una primera barrera protectora antes de 
lanzarnos a hacer **comparaciones múltiples**.

Entre los métodos de ajuste, podemos distinguir entre 
  1. Métodos centrados en controlar el **family-wise error rate (FWER)**, cuyo credo 
  es "Si cometo un solo error tipo I todas mis conclusiones se desmoronarán".
  2. Métodos centrados en controlar el **false discovery rate (FDR)**, que se 
  corresponde con el credo (considerablemente más optimista) 
  "vamos a intentar estimar cuántos errores tipo I cometo y a no pasarme de
  cierto número (pero no pasa nada si hay algún error)".
  
Podemos emplear `R` base para realizar los tests post-hoc...

```{r}
# Bonferroni es bastante conservador, pero es un ajuste muy conocido
pairwise.t.test(iris$Sepal.Length, iris$Species, p.adjust.method = "bonferroni")
# Los métodos fdr son "BH" (aka "fdr") and "BY".
pairwise.t.test(iris$Sepal.Length, iris$Species, p.adjust.method = "fdr")
```

... o bien el paquete `emmeans` (que tiene ciertas ventajas, como veremos):

```{r}
library("emmeans")
v_model_emms = emmeans(v_model, "Species")
pairs(v_model_emms, adjust="bonferroni", infer=c(TRUE, TRUE))
pairs(v_model_emms, adjust="fdr", infer = c(TRUE, TRUE))

# una de las ventajas de emmeans es que podemos calcular tamaños de efecto 
# para las medias aunque, tal y como se menciona en la documentación: 
# "there is substantial disagreement among practitioners on what is the appropriate 
# sigma to use in computing effect sizes; or, indeed, whether any effect-size 
# measure is appropriate for some situations"
eff_size(v_model_emms, sigma=sigma(v_model), edf = 147)
```

### Ejemplo: Contrastes con emmeans
Una desventaja de codificar los contrastes con `contrasts` es que hay que prestar
atención a los detalles (y el diablo esta en los detalles). Por ejemplo, ¿de dónde
sale el `3` del contraste `"V - setosa" = c(-2, 1, 1) / 3`? Además, cuando los
análisis de ANOVA se compliquen las cosas se pondrán realmente feas. 

Sirva el ejemplo de `contrasts` para resaltar que los coeficientes de regresión
nos permiten hacer **contrastes planeados**. Sin embargo, a partir de ahora 
calcularemos dichos contrastes con `emmeans`: 

```{r}
emmeans(v_model, "Species") %>% 
  # ¡Fíjate que los denominadores ahora sí son comprensibles!
  contrast(method = list('V-Setosa' = c(-1, 0.5, 0.5), 'I - II' = c(0, 1, -1)), 
           infer = c(TRUE, TRUE)) 

# fíjate también en que los resultados con emmeans coinciden con los coeficientes
# de summary (gracias a haber usado la función contrastS)
summary(v_model)

# En el futuro, evitaremos el uso de contrastS y usaremos emmeans
```



### Ejemplo: asunciones de ANOVA

En general, ANOVA asume:

* Las observaciones son independientes dentro de los grupos y entre los grupos.
* Los datos dentro de cada grupo son normales.
* La variabilidad dentro de cada grupo es aproximadamente igual a la  
variabilidad en los otros grupos. 

```{r}
plot(v_model, which = c(1, 2), ask=FALSE)
# o bien
plot(check_normality(v_model), type = "qq", detrend = TRUE)
check_homogeneity(v_model) # oooooohhhhhhh nooooooooooooo :(
```


### Ejemplo: ANCOVA
El dataset `anxiety` proporciona la puntuación de ansiedad, medida antes 
y después de aplicar un tratamiento contra la ansiedad, de tres grupos de personas
que practican ejercicios físicos en diferentes niveles 
(grp1: basal, grp2: moderado y grp3: alto). Aunque no tenemos ninguna hipótesis
específica, hagamos un análisis de los datos...

```{r}
anxiety = read.csv("data/anxiety.csv")
head(anxiety)

# 1) Vis...
ggplot(anxiety, aes(x = pretest, y = posttest, col = group)) +
  geom_point() + 
  geom_smooth(method="lm")

# 2) Contrates 
# No tenemos hipótesis :(

# 3) Anova + asunciones
anxiety_lm = lm(posttest ~ pretest + group, anxiety)
plot(anxiety_lm, which = c(1, 2), ask=FALSE)

anxiety_aov = Anova(anxiety_lm, type=3)
print(anxiety_aov)
eta_squared(anxiety_aov) 


# 4) Posthoc tests!
# ...
```

¡Ojo, queremos comparar diferencias entre las medias ajustadas! La función
pairwise.t.test() no usará medias ajustadas, por lo que debemos emplear 
`emmeans`:

```{r}
pairs(
  emmeans(anxiety_lm, "group", adjust = "Tukey"),
  infer = c(TRUE, TRUE)
)
```

# ANOVA factorial
Los diseño de **ANOVA factoriales (factorial = más de un factor)** permiten el efecto
individual y conjunto de uno o más factores. Podemos distinguir varios tipos de
análisis factoriales...

* ... Diseños independientes, 
* Diseños con medidas repetidas, 
* Diseños mixtos, ...

... que, como veremos, plantean ciertas diferencias en los modelos. En cualquier
caso, en los diseños factoriales lo que primero debemos comprender es el concepto
de **interacción**.

## ANOVA factorial independiente
### Ejemplo: Sin interacción entre los factores principales
Estudiamos el efecto de tres drogas sobre el tiempo de reacción (una de ellas placebo)
teniendo en cuenta además el sexo de los pacientes que toman el medicamento. Supongamos que 
el efecto de las drogas y edad se mide  en términos de reducción del tiempo de 
reacción a algún estímulo y que se obtienen los resultados del fichero
"drugs_1.csv". Visualiza el efecto de las drogas y sexo en los tiempos de reacción
y propón un modelo.

```{r}
drugs_df_1 = 
  read.csv("data/drugs_1.csv") %>%
  mutate(drug = factor(drug), sex = factor(sex))

# interaction.plot(drugs_df$sex, drugs_df$drug, response = drugs_df$response_time)
ggplot(drugs_df_1, aes(x=sex, y=response_time, col=drug)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=drug)) + 
  ggtitle("Data")

```

```{r}
drugs_model_1 = lm(response_time ~ sex + drug, data = drugs_df_1)
drugs_df_1$predictions = predict(drugs_model_1)

ggplot(drugs_df_1, aes(x=sex, y=predictions, col=drug)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=drug)) + 
  ggtitle("Predictions")
```


### Ejemplo: interacciones entre los factores principales
Repite el ejercicio anterior para los datos experimentales "drugs_2.csv".

```{r}
drugs_df_2 = 
  read.csv("data/drugs_2.csv") %>%
  mutate(drug = factor(drug), sex = factor(sex))

# interaction.plot(drugs_df$sex, drugs_df$drug, response = drugs_df$response_time)
ggplot(drugs_df_2, aes(x=sex, y=response_time, col=drug)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=drug)) + 
  ggtitle("Data")
```

```{r}
drugs_model_2 = lm(response_time ~ sex + drug, data = drugs_df_2)
drugs_df_2$predictions = predict(drugs_model_2)

ggplot(drugs_df_2, aes(x=sex, y=predictions, col=drug)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=drug)) + 
  ggtitle("Predictions")
```

Uuuuups, las predicciones son malíiiiiiisimas... El modelo no es capaz de 
capturar **las interacciones** presentes en los datos.

### Ejemplo: modelado de interacciones 
Para modelar interacciones...

```{r}
drugs_model_2 = lm(response_time ~ sex * drug, data = drugs_df_2) 
# o de forma equivalente
#drugs_model_2 = lm(response_time ~ sex + drug + sex:drug, data = drugs_df_2)
drugs_df_2$predictions = predict(drugs_model_2)

ggplot(drugs_df_2, aes(x=sex, y=predictions, col=drug)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=drug))
```


### Ejemplo: completando el análisis para drugs_model_2
Una vez aclarado el concepto de interacción podemos completar el análisis 
para `drugs_df_2`. 

```{r}
# 2) Contrastes: aunque hemos dejado contrasts de lado, es recomendable 
# planear los contrastes antes de correr ANOVA. 
# ¡Ojo! ahora creamos listas de contrastes

drugs_contrasts = list(
  "_Drugs-Placebo" = c(0.5, 0.5, -1), 
  "_A - B" = c(1, -1, 0)
)

# 3) ANOVA 
drugs_model_2 = lm(response_time ~ sex * drug, data = drugs_df_2)
print(Anova(drugs_model_2, type = 3))
eta_squared(drugs_model_2)
# Omitimos los plot de comprobación por sencillez...(comprueba que son correctos)
# plot(drugs_model_2, ask=FALSE)

# 4) contrastes
# Contrastes principales para drogas
emmeans(drugs_model_2, ~ drug) %>% 
  contrast(method = list("drugs" = drugs_contrasts))
# Contrastes para interacciones 
emmeans(drugs_model_2, ~ drug | sex) %>% 
  contrast(interaction = list("drugs" = drugs_contrasts, "sex" = "consec"), by=NULL)
```

Lo más interesante del código anterior es reflexionar sobre cada uno de los 
contrastes y su significado. Los contrastes básicos (`sex`, `Drugs-Placebo`, `A - B`)
deberían ser claros pero, ¿qué significan los contrastes para interacciones?

* `sex1:drug_Drugs-Placebo`: El efecto `Drugs-Placebo` es diferente en hombres y mujeres? 
Es decir, ¿el efecto de placebo Vs drogas es comparable en hombres y mujeres?
* `sex1:drug_A - B`: El efecto `drug_A - B` es diferente en hombres y mujeres? Es
decir, ¿el efecto droga A Vs droga B es comparable en hombres y mujeres?


### Ejemplo: visualización de los resultados de un contraste con interacciones
Veamos cómo visualizar que las interacciones entre contrastes y sexo son
significativas...

```{r}
contraste_1 = drugs_df_2 %>% mutate(drug = fct_recode(drug, 'Drug' = 'A', 'Drug' = 'B'))
contraste_2 = drugs_df_2 %>% filter(drug != "Placebo") %>% mutate(drug = fct_drop(drug)) 

ggplot(contraste_1, aes(x=drug, y=response_time, col=sex)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=sex))

ggplot(contraste_2, aes(x=drug, y=response_time, col=sex)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=sex))
```

En ambos casos, las pendientes de los grupos son distintas, lo que apoya que 
hay interacciones en los datos. 

Fíjate que, si las interacciones son significativas, la interpretación de los 
efectos principales no tiene sentido. Por ejemplo, en el contraste 2, la
droga B aumenta el tiempo de respuesta para las mujeres, pero lo disminuye 
para hombres. Por tanto, responder a ¿disminuye la droga B el tiempo de 
respuesta (para hombres y mujeres)? da una imagen incompleta del problema.

NO INTERPRETES LOS EFECTOS PRINCIPALES SI LA INTERACCIÓN ES SIGNIFICATIVA.

### Ejemplo: análisis Posthoc sobre las interacciones

```{r}
ggplot(drugs_df_2, aes(x=sex, y=response_time, col = drug)) + 
  stat_summary() + 
  stat_summary(geom="line", aes(group = drug))

drugs_emms = emmeans(drugs_model_2, ~ drug | sex) 
contrast(drugs_emms, interaction = list(drug="pairwise", sex='consec'), by=NULL, 
         adjust = "fdr")
```


## ANOVA factorial con medidas repetidas
Considera un experimento en el que a cada paciente se le realizan
tres mediciones: una al comenzar la prueba, otra medición tras probar el tratamiento
A, y otra medición tras probar el tratamiento B...

Los tests F en ANOVA asumen que las medidas son independientes. Cuando se 
utilizan **medidas repetidas** como en el ejemplo anterior, se viola esta 
suposición. Por tanto, cuando tenemos **ANOVA con medidas repetidas** 
debemos "cambiar" este supuesto por otro válido. Se asume que la relación entre 
pares de condiciones experimentales es similar. A este supuesto se le conoce como
**esfericidad**. De forma práctica...

1. La esfericidad se puede evaluar mediante el **test de Mauchly**. 
2. ¿Qué hacer si se viola la asunción de esfericidad? Existen correcciones 
para intentar aliviar este problema. Las más conocidas se deben a 
Greenhouse y Geisser (GG) y Huynh y Feldt (HF).  La recomendación general
es que si la esfericidad es mayor que 0.75 (sobre un máximo de 1) se debe usar
HF; en otro caso debe usarse la corrección de GG.

Desafortunadamente, el test `car::Anova` no incorpora correcciones contra 
la violación de esfericidad por lo que lo cambiaremos por `afex::aov_4`.

### Ejemplo: ANOVA factorial con medidas repetidas
Existe evidencia de que las actitudes hacia ciertos estímulos se pueden cambiar 
utilizando imágenes positivas. Como parte de una iniciativa para detener el 
consumo excesivo de alcohol en los adolescentes, el gobierno financió un estudio
para determinar si imágenes negativas podrían usarse para hacer que las 
actitudes de los adolescentes hacia el alcohol sean más negativas. Cada participante
en cada estudio vio un total de nueve anuncios simulados en tres sesiones. En 
una sesión, cada partipante ve tres anuncios (de cerveza, vino o agua); cada anuncio
tiene una actitud asociada (positiva, negativa o neutra). Al cabo de las 3 sesiones,
las variables se cruzan completamente produciendo 9 condiciones experimentales. 
Después de cada anuncio, se pidió a los participantes que calificaran las bebidas 
en una escala que iba desde -100 (me disgusta mucho) pasando por 0 (neutral) 
hasta 100 (me gusta mucho). El orden de los anuncios fue aleatorio, al igual que el orden en que las personas participaron en las tres sesiones. Datos en "data/attitude_long.dat"
(o "attitude.dat" para un reto).

```{r}
# Los datos en attitude.dat no son adecuados para anova... hay que arreglarlo!
attitude_df = read.table("data/attitude.dat", header = TRUE)

attitude_df_long = 
  attitude_df %>% 
  pivot_longer(beer_pos:water_neu, names_to = 'name', values_to = 'attitude') %>% 
  separate(name, into=c('drink', 'imagery'), sep = '_') %>% 
  mutate_if(is.character, as.factor)

```

```{r}
# 1) plot
attitude_df_long = read.table("data/attitude_long.dat", header=TRUE, 
                              stringsAsFactors = TRUE)
head(attitude_df_long)
ggplot(attitude_df_long, aes(x=drink, y=attitude, fill=imagery)) + geom_boxplot()

ggplot(attitude_df_long, aes(x=drink, y=attitude, col=imagery)) + 
  stat_summary() + 
  stat_summary(geom="line", aes(group=imagery))
```


```{r}
library('afex')

# 2) Contrastes: usaremos agua para comparar las bebidas alcohólicas y no-alcohólicas
drinks_contrasts = list(
  "Alcohol-Water" = c(0.5, -1, 0.5),
  "Beer-Wine" = c(1, 0, -1)
)
imagery_contrasts = list(
  "Others-Neutral" = c(0.5, -1, 0.5),
  "Pos-Neg" = c(-1, 0, 1)
)

# 3) ANOVA y asunciones
attitude_model = aov_4(attitude ~ drink * imagery + (drink * imagery | participant), 
                       data = attitude_df_long, observed=NULL)
# El effect size se corresponde con ges (generalized eta squared)
summary(attitude_model)

# asunciones
plot(check_normality(attitude_model), "qq", detrend = TRUE)
check_sphericity(attitude_model) # ya lo sabíamos :(
```

```{r}
# 4.a) Contrastes ...
emm = emmeans(attitude_model, ~ drink | imagery)
interaction_contrasts = list(
  "drink" = drinks_contrasts, 
  "imagery" = imagery_contrasts 
)

# 4.b) Test post-hoc
contrast(emm, interaction = interaction_contrasts, by = NULL)
attitude_emms = emmeans(attitude_model, ~ imagery | drink)
contrast(attitude_emms, interaction = list(imagery = "pairwise", drink = "consec"),
         by=NULL, adjust = "fdr")

# Visualización de apoyo a los contrastes/tests
ggplot(attitude_df_long, aes(x = drink, y = attitude, col = imagery)) + 
  stat_summary() + 
  stat_summary(geom="line", aes(group = imagery))
```

Como nota para cerrar ANOVA, una alternativa más flexible a estos modelos 
son los Linear Mixture Models (LMMs), que pueden manejar datos no-independientes,
no-esféricos, etc. Los paquetes principales en `R` son `nlme` y `lme4`.

### Ejercicio: Ratas
Como parte de una investigación de agentes tóxicos, se asignaron 48 ratas a 3 
venenos (I,II,III) y 4 tratamientos (A,B,C,D). La respuesta fue el tiempo de
supervivencia en decenas de horas. Realiza una análisis ANOVA completo de los
datos.

```{r}
rats_df = read.csv("data/rats.csv")

# 1) vis
ggplot(rats_df, aes(x = poison, y = time, col = treat)) + 
  stat_summary() + 
  stat_summary(geom = "line", aes(group = treat))

# 2) 
rats_model = lm(time ~ poison * treat, data = rats_df)
# Los residuos no son normales :(
plot(check_normality(rats_model), "qq", detrend = TRUE)
# varianza parece depender de la predicción! :(
plot(rats_model,ask = FALSE, which = 3)

# No tiene sentido seguir con el análisis...

```


# Análisis no paramétrico
Hemos visto que la Normalidad de los datos es una asunción importante de los 
métodos vistos hasta el momento. ¿Qué hacer si los datos violan claramente la
normalidad? 

Los **metodos no paramétricos** permiten realizar análisis estadísticos sin 
asumir ninguna distribución de los datos. A cambio, pierden potencia en los 
contrastes.

A grandes rasgos tenemos...
*  Como alternativa a t-test independiente $\rightarrow$ Mann–Whitney test o 
Wilcoxon’s rank-sum test $\rightarrow$ `wilcox.test`.
* Como alternativa a t-test apareado $\rightarrow$ Wilcoxon signed-rank test 
$\rightarrow$ `wilcox.test`.
* Como alternativa a One-way ANOVA $\rightarrow$  Kruskal–Wallis test $\rightarrow$ `kruskal.test`.
* Como alternativa a Repeated Measures ANOVA $\rightarrow$  Friedman's ANOVA $\rightarrow$ `friedman.test`.

### Ejemplo: Wilcoxon's rank-sum
El gasto cardı́aco (litros/minuto) se midió por termodilución en una muestra
aleatoria simple de 15 pacientes operados de corazón. Deseamos saber si
podemos concluir que la media de la población es diferente de 5.05.

```{r}
data = c(4.91, 4.10, 6.74, 7.27, 7.42, 7.50, 6.56, 4.64, 5.98, 3.14, 3.23,
5.80,6.17,5.39, 5.77)
w_test = wilcox.test(data, mu = 5.05)
print(w_test)
w_test %>% rank_biserial()
```

### Ejercicio: Wilcoxon para datos apareados
En un estudio, se midieron los estreses hemodinámicos en sujetos sometidos a
colecistectomı́a laparoscópica. Una variable de interés es el volumen diastólico
final ventricular (LVEDV) medido en mililitros. Los datos se encuentra en
“lvedv.tsv”. El “baseline” se refiere a una medición tomada 5 minutos después
de la inducción de la anestesia, y el término “5 minutes” se refiere a una
medición tomada 5 minutos después del “baseline”. ¿Hay cambios en los
niveles de LVEDV durante la intervención?
```{r}
lvedv = read.table("data/lvedv.tsv", header = TRUE)
w_test = wilcox.test(lvedv$baseline, lvedv$X5_minutes, paired = TRUE)
print(w_test)
w_test %>% rank_biserial()
```

### Ejercicio: Wilcoxon de una sola cola
Se ha diseñado un experimento para evaluar los efectos de la inhalación
prolongada de óxido de cadmio. Quince animales de laboratorio sirvieron como
sujetos experimentales, mientras que 10 animales similares sirvieron como
controles. La variable de interés fue el nivel de hemoglobina después del
experimento. Los resultados se encuentran en “cadmium.csv”. Deseamos saber
si podemos concluir que la inhalación prolongada de óxido de cadmio reduce el
nivel de hemoglobina

```{r}
dat = read.table("data/cadmium.csv", header = TRUE, sep = ",")
w_test = wilcox.test(
  dat %>% filter(class == "exposed") %>% .$hemoglobin,
  dat %>% filter(class == "unexposed") %>% .$hemoglobin,
  alternative = "less"
)
print(w_test)
w_test %>% rank_biserial()
```

# Ejemplo: Kruskal-Wallis y análisis post-hoc
En `PlantGrowth` tenemos los resultados de un experimento para comparar los 
rendimientos (medidos por el peso en seco de las plantas) obtenidos bajo un 
control y dos tratamientos diferentes para hacer crecer a las plantas.


```{r}
data("PlantGrowth")
head(PlantGrowth)
# Alternativa: kruskal.test(weight ~ group, data = PlantGrowth)
kw_test = kruskal.test(PlantGrowth$weight, PlantGrowth$group)
kw_test %>% rank_epsilon_squared()


pairwise.wilcox.test(PlantGrowth$weight, PlantGrowth$group,
                 p.adjust.method = "BH")
```

# Ejemplo: Test de Friedman para medidas repetidas
El dataset `selfesteem` contiene la puntuación de autoestima de 10 personas 
con obesidad en tres momentos durante una dieta. El objetivo es determinar si 
su autoestima mejoró con la dieta.

```{r}
selfesteem = read.csv("data/selfesteem.csv")
head(selfesteem)

ggplot(selfesteem, aes(x=time, y=score)) + geom_boxplot()


# Alternativa: friedman.test(score ~ time | id, selfesteem)
f_test = friedman.test(selfesteem$score, groups = selfesteem$time, blocks = selfesteem$id)
f_test %>% kendalls_w()

pairwise.wilcox.test(selfesteem$score, selfesteem$time, paired = TRUE,
                     p.adjust.method = "bonferroni")
```


# Automatización de análisis

### Ejemplo: test y plots para varios ficheros
La carpeta "meta" contiene los datos de varios papers de los que se 
desea hacer un meta-análisis. Como primer paso, deseas verificar que los resultados
que obtienes sobre los datos son los mismos que se han reportado en los papers
originales. Para ello, leerás los datos (todos tienen dos columnas: response y group),
ejecutarás un T-test y generarás un gráfico donde se comparen las respuestas para 
los niveles de group. Los gráficos resultantes se guardarán en la carpeta "meta/images"
y los p-valores de los tests en un solo `data.frame` *p-values*.

```{r}
base_path = "data/meta"
images_path = file.path(base_path, "images")
print(images_path)
dir.create(images_path, showWarnings = FALSE)
files = list.files(base_path, pattern=".csv")

p_values = data.frame()

for (file in files) {
  df = read.csv(file.path(base_path, file))
  test = t.test(response ~ group, df)
  result = data.frame("filename" = file, "p_value" = test$p.value)
  p_values = rbind(p_values, result)
  
  plot = ggplot(df, aes(x = group, y = response, fill = group)) + geom_boxplot()
  image_name = gsub(".csv", ".png", file)
  ggsave(file.path(images_path, image_name), plot)
}
print(p_values)
write.csv(p_values, "p_values.csv", row.names = FALSE)

# Comprueba además que se han generado imágenes en "data/meta/images"
```

