---
title: "Análisis estadístico"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Modelado estadístico: las dos culturas
En el artículo clásico [Statistical modeling: The two cultures]((https://projecteuclid.org/journals/statistical-science/volume-16/issue-3/Statistical-Modeling--The-Two-Cultures-with-comments-and-a/10.1214/ss/1009213726.full)) encontramos 

> There are two cultures in the use of statistical modeling to reach conclusions from
data. One assumes that the data are generated by a given stochastic data model. The
other uses algorithmic models and treats the data mechanism as unknown. (Leo Breiman)

* *Explanatory modeling*: modelos estadísticos empleados para probar una teoría (causal?).
Para ello se emplean variables con un significado científico claro y se evalúa si tienen 
una relación *significativa* con la variable de interés. $\rightarrow$ "Estadística clásica"
basada en **modelos lineales**.
* *Predictive modeling*: modelos cuyo propósito es predecir observaciones nuevas 
o futuras. $\rightarrow$ **Aprendizaje automático** (*machine learning*).

En este notebooks nos centraremos en modelos lineales y en los métodos de inferencia
clásica. El siguiente notebook cubre modelos basados en aprendizaje automático.

(Otras lecturas interesante sobre las dos culturas es [To explain or to predict?](https://www.stat.berkeley.edu/~aldous/157/Papers/shmueli.pdf).)

## Regression is all you need
### Regresión simple

El modelo básico sobre el que se construye gran parte de la "Estadística clásica"
es el modelo de **regresión lineal**:
$$y = a + b\cdot x + \epsilon$$
donde $\epsilon \sim \mathcal{N}(0, \sigma^2)$.

Es instructivo simular datos que sigan este modelo para entender el significado
de la ecuación:

```{r sim}
library('tidyverse') 

x = seq(-2, 2, 0.1)
expected_behaviour = 2 + 3 * x  # a = 2 y b = 3
epsilon = rnorm(length(x), sd = 1)
y = expected_behaviour + epsilon

plot(x, y)
lines(x, expected_behaviour, col = 2)
```

Podemos pensar que `expected_behaviour` es el comportamiento medio o esperado
en la población de interés, mientras que $\epsilon$ representan fluctuaciones 
aleatorias (bien debidas a errores del proceso de medición o que el proceso 
estudiado tiene cierta aleatoriedad). Además, la relación entre $x$ e $y$ es muy
específica. Si aumenta (disminuye) $x$ aumenta (disminuye) $y$. Además, un 
incremento de una unidad en $x$ siempre produce el mismo incremento en $y$ (ídem
si $x$ disminuye). Se dice que la relación entre $x$ e $y$ es **lineal**.

La primera pregunta a la que nos enfrentamos es la siguiente. Dados los datos
$(x, y)$, ¿podemos estimar `expected behaviour`? 

![](https://media.giphy.com/media/l0ErOholJjSmFlMFG/giphy.gif)
## Ejemplo: lm

```{r lm}
# 1) crear un modelo lineal
df = data.frame(xx = x, yy = y)
naive_model = lm(yy ~ xx, data = df)
# 2) obtener estimaciones de a y b
summary(naive_model)
# 3) visualizar el ajuste
plot(x, y)
lines(x, expected_behaviour, col = 2)
lines(x, predict(naive_model), col = 3)
legend("topleft", c("Ground truth", "fitted"), col=2:3, lwd=2)
```

Dado que las estimaciones incorporan el error de estimación, es posible realizar
inferencia acerca de la **significación** de los parámetros.

## Ejemplo: inferencia con lm
Un estudiante de biología desea determinar la relación entre
temperatura ambiente y frecuencia cardíaca en la rana leopardo, *Rana pipiens*.
Para ello, manipula la temperatura en incrementos de 2ºC que van desde
2ºC a 18ºC, registrando la frecuencia cardíaca (pulsaciones por minuto) en cada
intervalo. Los datos están disponibles en "hr.csv".

```{r lm_inference}
# 1) leer los datos
frog_df = read.table("data/hr.csv", header = TRUE)
# 2) Crear un modelo lineal
frog_model = lm(heart_rate ~ temperature, data = frog_df)
# 3) Inferencia
summary(frog_model)
```

## Ejercicio: predicción de AT abdominal
Després et al. [^1] señalan que el tejido adiposo (AT) se asocia con complicaciones
metabólicas consideradas como factores de riesgo para la enfermedad 
cardiovascular. Es importante, afirman, medir la cantidad de AT intraabdominal
como parte de la evaluación del riesgo de enfermedad cardiovascular de un 
individuo. Després y sus colegas realizaron un estudio para predecir la 
cantidad de AT abdominal a partir de simples mediciones antropométricas. 

Entre las medidas tomadas en cada sujeto, se incluyó la AT abdominal obtenida por
TC y la circunferencia de la cintura (datos en Wat.csv''). Una pregunta de 
interés es cómo de bien se puede predecir y estimar la AT abdominal a partir del 
conocimiento de la circunferencia de la cintura. Construye un modelo lineal y
plotea sus predicciones. ¿Es significativa la relación entre AT y la circunferencia
de la cintura?

[^1]: J. Després, D. Homme, M. Pouliot, A. Tremblay,
and C. Bouchard, ``Estimation of Deep Abdominal Adipose-Tissue Accumulation 
from Simple Anthropometric Measurements in Men'' American Journal of Clinical
Nutrition, 54 (1991), 471–477.

```{r}

at_df = read.table("data/at.csv", header=TRUE, sep = ",") 
names(at_df) = c("subject", "waist", "AT")
at_model = lm(AT ~ waist, data = at_df)
print(at_model)

plot(AT ~ waist, data = at_df, xlab = "waist circumference (cm)",
     ylab = "deep abdominal AT (cm2)")
abline(at_model, col = 2, lwd = 2)
```


El diseño experimental y los resultados de la inferencia en el ejemplo de las ranas
nos invitan a concluirque "el aumento de la temperatura *causa* un incremento de 
la frecuencia cardíaca". Sin embargo, esto no es correcto. Por muy fuerte que 
parezca la relación entre las variables $x$ e $y$, **nunca debemos interpretar 
una variable como la causa de la otra**. Una relación significativa entre $x$ e 
$y$ puede ocurrir por varios motivos:

1. $x$ causa $y$.
2. $y$ causa $x$.
3. Existe un tercer factor (llamado *variable de confusión*) que, bien directa
o indirectamente, causa $x$ e $y$.

![](https://qph.fs.quoracdn.net/main-qimg-13d22f6fda3811a9108d18b71c46e933-pjlq)

Evidentemente cualquier interpretación está supeditada a que el modelo sea 
correcto. Debemos ser muy cuidadosos a la hora de verificar que se cumplan las
asunciones del modelo de regresión lineal. Podemos usar el acrónimo **LINE** para
recordar las asunciones más importantes del modelo: 
**Linear, Independent, Normal, Equal variances**.

### Ejemplo: evaluación del modelo `naive_model`
```{r}
plot(naive_model, ask = FALSE)
```

La gráfica más difícil de interpretar es `Residuals Vs Leverage``:
![](figures/lev_ll-1.png)
![](figures/lev_lh-1.png)
![](figures/lev_hl-1.png)
![](figures/lev_ll-1.png)

### Ejercicio: asunciones en el problema de AT abdominal
¿Se cumplan las asunciones de la regresión lineal en el problema de AT abdominal?
```{r bondad_at}
plot(at_model, ask = FALSE)
library(lmtest)
lmtest::bptest(at_model) # Heterocedastic!!!!
```

### Regresión múltiple
Para lidiar con situaciones como la ilustrada en el gráfico anterior 
necesitamos emplear modelos de **regresión múltiple**, dado que estos permiten 
"controlar" las variables de confusión. Crear un modelo de regresión múltiple
es análogo al caso unidimensional...

### Ejemplo: regresión múltiple
Jansen y Keller[^2] utilizaron la edad y el nivel de educación para predecir la
capacidad de dirigir la atención (CDA) en sujetos ancianos. CDA se refiere a
los mecanismos neuronales que enfocan la mente en lo que es significativo al
tiempo que bloquea las distracciones. El estudio recopiló información sobre 71
mujeres mayores con estado mental normal. En este estudio las puntuaciones
más altas se corresponden con un mejor funcionamiento de la atención. Las
mediciones en CDA, edad en años y el nivel de educación (años de escolaridad)
están recogidos en “cda.csv”. Crea un modelo de regresión múltiple para predecir la
puntuación de CDA.

[^2] D. Jansen, M. Keller, Çognitive Function in Community-Dwelling Elderly Women”, Journal of
Gerontological Nursing, 29 (2003), 34-43.

```{r cda}
df = read.csv("data/cda.csv")
cda_model = lm(CDA ~ ., df)
df$predictions = predict(cda_model)

summary(cda_model)
```

Hasta ahora solo hemos usado datos continuos, pero nada evita usar datos categóricos
como predictores. ¡Ojo! Los coeficientes asociados a datos categóricos no deben 
interpretarse como una pendiente.

### Ejemplo: regresión múltiple con datos categóricos
Construye un modelo de regresión lineal para predecir el peso de una persona a partir
de los datos contenidos en "antrop.csv". Interpreta los coeficientes de la regresión.

```{r}
antrop = read.csv("data/antrop.csv")
antrop = mutate(antrop, male = factor(male))
antrop_model = lm(weight ~ height + male, data = antrop)
summary(antrop_model)

male_preds = predict(
  antrop_model, 
  antrop %>% mutate(male = 1, male = factor(male, levels = c(0, 1)))
)
female_preds = predict(
  antrop_model, 
  antrop %>% mutate(male = 0, male = factor(male, levels = c(0, 1)))
)
plot(weight ~ height, antrop)
lines(antrop$height, male_preds, col = 2, type = "l", lwd=2)
lines(antrop$height, female_preds, col = 3, lwd=2)
summary(antrop_model)
```


### Ejercicio: Howell
Los datos contenidos en "howell1.csv" son datos censales parciales del 
área !Kung San compilados a partir de entrevistas realizadas a finales de la década
de 1960. Crea un modelo para predecir el peso de los individuos a partir 
de la altura y el sexo. Evalúa la bondad del modelo.

```{r howell1}
howell = read.csv("data/howell1.csv", sep = ";")
howell = mutate(howell, male = factor(male))
howell_model = lm(weight ~ height + male, data = howell)
summary(howell_model)

male_preds = predict(
  howell_model, 
  howell %>% mutate(male = 1, male = factor(male, levels = c(0, 1)))
)
female_preds = predict(
  howell_model, 
  howell %>% mutate(male = 0, male = factor(male, levels = c(0, 1)))
)
# plot(weight ~ height, howell)
plot(howell$height, male_preds, col = 2, type = "l")
lines(howell$height, female_preds, col = 3)
```


### Ejemplo: dummy variables y contrastes
El dataset `iris` (puedes obtenerlo con `data(iris)`) contiene medidas del sépalo
y pétalo de varias especies de iris. Construye un modelo lineal para predecir
la longitud del sépalo únicamente en funciónde la especie. Interpreta los coeficientes
de la regresión.

```{r iris}
data(iris)
iris_model = lm(Sepal.Length ~ Species, iris)
print(coef(iris_model))

plot(Sepal.Length ~ Species, iris)
predictions = predict(iris_model)
points(iris$Species, predictions, col = iris$Species, pch = 15)

plot(iris$Sepal.Length, col = iris$Species,
xlab = "Observation number", ylab = "Sepal Length")
points(predictions, col = iris$Species, cex = 0.7, pch = 15)
```

Al interpretar los coeficientes de la regresión, quizás hayas observado que 
`lm` ha tomado como referencia la especie `setosa`. Esto se puede observar usando
`contrasts`. De hecho, `contrast` se puede modificar para usar como referencia
otro nivel del factor:

### Ejemplo: contrastes
```{r contrastes}
contrasts(iris$Species)
# Usamos versicolor como referencia
contrasts(iris$Species) = contr.treatment(3, 2)
contrasts(iris$Species)
summary(lm(Sepal.Length ~ Species, iris))
```


## T-tests: comparación de dos grupos

## Ejemplo: dependen los datos
¿Depende la altura de los !Kung adultos del sexo del inviduo? Emplea los datos en 
"howell1.csv".

```{r kung_sex}
adult_howell = filter(howell, age >= 18)
height_model = lm(height ~ male, data = adult_howell)
summary(height_model)
```

### Ejercicio: histogramas 
Apoya tus conclusiones dibujando el histograma de las alturas por sexo

```{r}
ggplot(adult_howell, aes(x = height, fill=male)) + geom_density(alpha=0.2)
```

### Ejercicio: evaluación del modelo
¿Cumple el modelo las asunciones de la regresión lineal?
```{r}
hist(resid(height_model))
```

Lo cierto es que, aunque correcto, nuestra aproximación no es la habitual a la
hora de **comparar la media de dos poblaciones**. Si las poblaciones son normales
(o si podemos invocar el Teorema Central del Límite), podemos hacer uso del 
`t.test`.

### Ejemplo: T-test para comparación de medias
```{r ttest}
male_heights = filter(adult_howell, male == 1)$height
female_heights = filter(adult_howell, male == 0)$height
t.test(male_heights, female_heights)
```

### Ejemplo: T-test de una sola cola 
¿Podemos concluir que los hombres son más altos que las mujeres?

```{r one_sided_ttest}
t.test(male_heights, female_heights, alternative="greater")
```

### Ejercicio: T-test apareado
John M. Morton et al. [^3] examinaron la función de la vesı́cula biliar antes y
después de la fundoplicatura, una cirugı́a para detener el reflujo. Los autores
midieron la funcionalidad de la vesı́cula biliar calculando la fracción de eyección
de la vesı́cula biliar (GBEF) antes y después de la fundoplicatura. El objetivo de
la fundoplicatura es aumentar la GBEF, que se mide como un porcentaje. ¿Hay
evidencia para concluir que la fundoplicatura aumenta el funcionamiento de la
GBEF? Datos en "gbef_long.csv" (o "gbef.csv", para un reto).

```{r gbef}
# df = read.table("data/gbef_long.csv", header = TRUE)
df = read.table("data/gbef.csv")
df
df = 
  df %>% 
  pivot_longer(-(V1:V2), names_to="junk",  values_to = "gbef") %>% 
  select(-V2, -junk) %>%
  rename(class = V1)
df_sp = split(df, df$class)
t.test(df_sp$Postop$gbef, df_sp$Preop$gbef, paired = TRUE, alternative = "greater")
```

### Ejercicio: evaluación del modelo de datos apareados
```{r paired_hist}
d = df_sp$Postop$gbef - df_sp$Preop$gbef
hist(d)
```

## ANOVA: comparación de medias para múltiples grupos


### Ejemplo: One-way ANOVA
Veinticuatro animales fueron asignados aleatoriamente a cuatro dietas diferentes
y se tomaron muestras de sangre en un orden aleatorio. Se midió el tiempo de 
coagulación de la sangre. Datos en "coagulation.csv". ¿Influye la dieta en 
el tiempo de coagulación?


```{r coagulation}
library("car")
coagulation = read.csv("data/coagulation.csv")
options(contrasts = c("contr.sum", "contr.poly")) # for type 3 contrast
coagulation_lm = lm(coag ~ diet, data = coagulation)
coagulation_aov = Anova(coagulation_lm, type = 3)
print(coagulation_aov)
```


```{r coagulation_plot}
print(ggplot(coagulation, aes(x = diet, y = coag, fill = diet)) +
        geom_boxplot() + coord_flip())
```


En general, ANOVA asume:

* Las observaciones son independientes dentro de los grupos y entre los grupos.
* Los datos dentro de cada grupo son normales.
* La variabilidad dentro de cada grupo es aproximadamente igual a la  
variabilidad en los otros grupos. 

```{r}
plot(coagulation_lm, which = c(1, 2), ask=FALSE)
```


```{r}
pairwise.t.test(coagulation$coag, coagulation$diet, p.adj = "bonf")
pairwise.t.test(coagulation$coag, coagulation$diet, p.adj = "BH")  # Benjamini–Hochberg
```

```{r}
library("agricolae")
HSD.test(coagulation_lm, "diet", group=TRUE, console=TRUE)
```

<!-- https://digitalcommons.wayne.edu/cgi/viewcontent.cgi?article=2088&context=jmasm -->
<!-- https://stats.stackexchange.com/questions/2962/omega-squared-for-measure-of-effect-in-r -->
```{r}
library("multcomp") #glht
data("anxiety", package = "datarium")
anxiety <- anxiety %>%
  dplyr::select(id, group, t1, t3) %>%
  rename(pretest = t1, posttest = t3)
anxiety[14, "posttest"] <- 19
```
```{r}
anxiety_lm = lm(posttest ~ pretest + group, anxiety)
Anova(anxiety_lm, type=3)
# we want to test differences between the adjusted means, we can use only
# the glht() function; the pairwise.t.test() function will not test the adjusted means. As such,
# we are limited to using Tukey or Dunnett’s post hoc tests.
postHocs<-glht(anxiety_lm, linfct = mcp(group = "Tukey"))
summary(postHocs)
confint(postHocs)
```


# TODO: ANCOVA

Los diseño de **ANOVA factoriales (factorial = más de un factor)** permiten el efecto
individual y conjunto de uno o más factores. Podemos distinguir varios tipos de
análisis factoriales:

* Diseños independientes.
* Diseños con medidas repetidas.
* Diseños mixtos.

## Ejemplo: Sin interacción entre los factores principales
Estudiamos el efecto de tres drogas sobre el tiempo de reacción, teniendo en 
cuenta además el sexo de los pacientes que toman el medicamento. Supongamos que 
el efecto de las drogas y edad se mide  en términos de reducción del tiempo de 
reacción a algún estímulo y que se obtienen los resultados del fichero
"drugs_1.csv". Visualiza el efecto de las drogas y sexo en los tiempos de reacción
y reflexiona sobre cómo modelarlo.

#TODO: remove
```{r GEN1}
drugs_df <- data.frame(drug=rep(c("A", "B", "C"), 10), sex=rep(c("Male", "Female"),15))
drugs_df$response_time = NA
drugs_df[drugs_df$drug == "A", "response_time"] = 10 + rnorm(10, sd=1) 
drugs_df[drugs_df$drug == "B", "response_time"] = 20 + rnorm(10, sd=1) 
drugs_df[drugs_df$drug == "C", "response_time"] = 30 + rnorm(10, sd=1) 
drugs_df[drugs_df$sex == "Female", "response_time"] =  drugs_df[drugs_df$sex == "Female", "response_time"] + rnorm(15, 4, sd=0.1)
write.csv(drugs_df, "data/drugs_1.csv", row.names = FALSE, )
```

```{r drugs_1}
drugs_df = 
  read.csv("data/drugs_1.csv") %>%
  mutate(drug = factor(drug), sex = factor(sex))

# interaction.plot(drugs_df$sex, drugs_df$drug, response = drugs_df$response_time)
ggplot(drugs_df, aes(x=drug, y=response_time, col=sex)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=sex))
```




