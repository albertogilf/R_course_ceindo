---
title: "Análisis estadístico"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Modelado estadístico: las dos culturas
En el artículo clásico [Statistical modeling: The two cultures]((https://projecteuclid.org/journals/statistical-science/volume-16/issue-3/Statistical-Modeling--The-Two-Cultures-with-comments-and-a/10.1214/ss/1009213726.full)) encontramos 

> There are two cultures in the use of statistical modeling to reach conclusions from
data. One assumes that the data are generated by a given stochastic data model. The
other uses algorithmic models and treats the data mechanism as unknown. (Leo Breiman)

* *Explanatory modeling*: modelos estadísticos empleados para probar una teoría (causal?).
Para ello se emplean variables con un significado científico claro y se evalúa si tienen 
una relación *significativa* con la variable de interés. $\rightarrow$ "Estadística clásica"
basada en **modelos lineales**.
* *Predictive modeling*: modelos cuyo propósito es predecir observaciones nuevas 
o futuras. $\rightarrow$ **Aprendizaje automático** (*machine learning*).

En este notebooks nos centraremos en modelos lineales y en los métodos de inferencia
clásica. El siguiente notebook cubre modelos basados en aprendizaje automático.

(Otras lecturas interesante sobre las dos culturas es [To explain or to predict?](https://www.stat.berkeley.edu/~aldous/157/Papers/shmueli.pdf).)

## Regression is all you need
### Regresión simple

El modelo básico sobre el que se construye gran parte de la "Estadística clásica"
es el modelo de **regresión lineal**:
$$y = a + b\cdot x + \epsilon$$
donde $\epsilon \sim \mathcal{N}(0, \sigma^2)$.

Es instructivo simular datos que sigan este modelo para entender el significado
de la ecuación:

```{r sim}
library('tidyverse') 

x = seq(-2, 2, 0.1)
expected_behaviour = 2 + 3 * x  # a = 2 y b = 3
epsilon = rnorm(length(x), sd = 1)
y = expected_behaviour + epsilon

plot(x, y)
lines(x, expected_behaviour, col = 2)
```

Podemos pensar que `expected_behaviour` es el comportamiento medio o esperado
en la población de interés, mientras que $\epsilon$ representan fluctuaciones 
aleatorias (bien debidas a errores del proceso de medición o que el proceso 
estudiado tiene cierta aleatoriedad). Además, la relación entre $x$ e $y$ es muy
específica. Si aumenta (disminuye) $x$ aumenta (disminuye) $y$. Además, un 
incremento de una unidad en $x$ siempre produce el mismo incremento en $y$ (ídem
si $x$ disminuye). Se dice que la relación entre $x$ e $y$ es **lineal**.

La primera pregunta a la que nos enfrentamos es la siguiente. Dados los datos
$(x, y)$, ¿podemos estimar `expected behaviour`? 

![](https://media.giphy.com/media/l0ErOholJjSmFlMFG/giphy.gif)
## Ejemplo: lm

```{r lm}
# 1) crear un modelo lineal
df = data.frame(xx = x, yy = y)
naive_model = lm(yy ~ xx, data = df)
# 2) obtener estimaciones de a y b
summary(naive_model)
# 3) visualizar el ajuste
plot(x, y)
lines(x, expected_behaviour, col = 2)
lines(x, predict(naive_model), col = 3)
legend("topleft", c("Ground truth", "fitted"), col=2:3, lwd=2)
```

Dado que las estimaciones incorporan el error de estimación, es posible realizar
inferencia acerca de la **significación** de los parámetros.

## Ejemplo: inferencia con lm
Un estudiante de biología desea determinar la relación entre
temperatura ambiente y frecuencia cardíaca en la rana leopardo, *Rana pipiens*.
Para ello, manipula la temperatura en incrementos de 2ºC que van desde
2ºC a 18ºC, registrando la frecuencia cardíaca (pulsaciones por minuto) en cada
intervalo. Los datos están disponibles en "hr.csv".

```{r lm_inference}
# 1) leer los datos
frog_df = read.table("data/hr.csv", header = TRUE)
# 2) Crear un modelo lineal
frog_model = lm(heart_rate ~ temperature, data = frog_df)
# 3) Inferencia
summary(frog_model)
```

## Ejercicio: predicción de AT abdominal
Després et al. [^1] señalan que el tejido adiposo (AT) se asocia con complicaciones
metabólicas consideradas como factores de riesgo para la enfermedad 
cardiovascular. Es importante, afirman, medir la cantidad de AT intraabdominal
como parte de la evaluación del riesgo de enfermedad cardiovascular de un 
individuo. Després y sus colegas realizaron un estudio para predecir la 
cantidad de AT abdominal a partir de simples mediciones antropométricas. 

Entre las medidas tomadas en cada sujeto, se incluyó la AT abdominal obtenida por
TC y la circunferencia de la cintura (datos en Wat.csv''). Una pregunta de 
interés es cómo de bien se puede predecir y estimar la AT abdominal a partir del 
conocimiento de la circunferencia de la cintura. Construye un modelo lineal y
plotea sus predicciones. ¿Es significativa la relación entre AT y la circunferencia
de la cintura?

[^1]: J. Després, D. Homme, M. Pouliot, A. Tremblay,
and C. Bouchard, ``Estimation of Deep Abdominal Adipose-Tissue Accumulation 
from Simple Anthropometric Measurements in Men'' American Journal of Clinical
Nutrition, 54 (1991), 471–477.

```{r}

at_df = read.table("data/at.csv", header=TRUE, sep = ",") 
names(at_df) = c("subject", "waist", "AT")
at_model = lm(AT ~ waist, data = at_df)
print(at_model)

plot(AT ~ waist, data = at_df, xlab = "waist circumference (cm)",
     ylab = "deep abdominal AT (cm2)")
abline(at_model, col = 2, lwd = 2)
```


El diseño experimental y los resultados de la inferencia en el ejemplo de las ranas
nos invitan a concluirque "el aumento de la temperatura *causa* un incremento de 
la frecuencia cardíaca". Sin embargo, esto no es correcto. Por muy fuerte que 
parezca la relación entre las variables $x$ e $y$, **nunca debemos interpretar 
una variable como la causa de la otra**. Una relación significativa entre $x$ e 
$y$ puede ocurrir por varios motivos:

1. $x$ causa $y$.
2. $y$ causa $x$.
3. Existe un tercer factor (llamado *variable de confusión*) que, bien directa
o indirectamente, causa $x$ e $y$.

![](https://qph.fs.quoracdn.net/main-qimg-13d22f6fda3811a9108d18b71c46e933-pjlq)

Evidentemente cualquier interpretación está supeditada a que el modelo sea 
correcto. Debemos ser muy cuidadosos a la hora de verificar que se cumplan las
asunciones del modelo de regresión lineal. Podemos usar el acrónimo **LINE** para
recordar las asunciones más importantes del modelo: 
**Linear, Independent, Normal, Equal variances**.

### Ejemplo: evaluación del modelo `naive_model`
```{r}
plot(naive_model, ask = FALSE)
```

La gráfica más difícil de interpretar es `Residuals Vs Leverage``:
![](figures/lev_ll-1.png)
![](figures/lev_lh-1.png)
![](figures/lev_hl-1.png)
![](figures/lev_ll-1.png)

### Ejercicio: asunciones en el problema de AT abdominal
¿Se cumplan las asunciones de la regresión lineal en el problema de AT abdominal?
```{r bondad_at}
plot(at_model, ask = FALSE)
library(lmtest)
lmtest::bptest(at_model) # Heterocedastic!!!!
```

### Regresión múltiple
Para lidiar con situaciones como la ilustrada en el gráfico anterior 
necesitamos emplear modelos de **regresión múltiple**, dado que estos permiten 
"controlar" las variables de confusión. Crear un modelo de regresión múltiple
es análogo al caso unidimensional...

### Ejemplo: regresión múltiple
Jansen y Keller[^2] utilizaron la edad y el nivel de educación para predecir la
capacidad de dirigir la atención (CDA) en sujetos ancianos. CDA se refiere a
los mecanismos neuronales que enfocan la mente en lo que es significativo al
tiempo que bloquea las distracciones. El estudio recopiló información sobre 71
mujeres mayores con estado mental normal. En este estudio las puntuaciones
más altas se corresponden con un mejor funcionamiento de la atención. Las
mediciones en CDA, edad en años y el nivel de educación (años de escolaridad)
están recogidos en “cda.csv”. Crea un modelo de regresión múltiple para predecir la
puntuación de CDA.

[^2] D. Jansen, M. Keller, Çognitive Function in Community-Dwelling Elderly Women”, Journal of
Gerontological Nursing, 29 (2003), 34-43.

```{r cda}
df = read.csv("data/cda.csv")
cda_model = lm(CDA ~ ., df)
df$predictions = predict(cda_model)

summary(cda_model)
```

Hasta ahora solo hemos usado datos continuos, pero nada evita usar datos categóricos
como predictores. ¡Ojo! Los coeficientes asociados a datos categóricos no deben 
interpretarse como una pendiente.

### Ejemplo: regresión múltiple con datos categóricos
Construye un modelo de regresión lineal para predecir el peso de una persona a partir
de los datos contenidos en "antrop.csv". Interpreta los coeficientes de la regresión.

```{r}
antrop = read.csv("data/antrop.csv")
antrop = mutate(antrop, male = factor(male))
antrop_model = lm(weight ~ height + male, data = antrop)
summary(antrop_model)

male_preds = predict(
  antrop_model, 
  antrop %>% mutate(male = 1, male = factor(male, levels = c(0, 1)))
)
female_preds = predict(
  antrop_model, 
  antrop %>% mutate(male = 0, male = factor(male, levels = c(0, 1)))
)
plot(weight ~ height, antrop)
lines(antrop$height, male_preds, col = 2, type = "l", lwd=2)
lines(antrop$height, female_preds, col = 3, lwd=2)
summary(antrop_model)
```


### Ejercicio: Howell
Los datos contenidos en "howell1.csv" son datos censales parciales del 
área !Kung San compilados a partir de entrevistas realizadas a finales de la década
de 1960. Crea un modelo para predecir el peso de los individuos a partir 
de la altura y el sexo. Evalúa la bondad del modelo.

```{r howell1}
howell = read.csv("data/howell1.csv", sep = ";")
howell = mutate(howell, male = factor(male))
howell_model = lm(weight ~ height + male, data = howell)
summary(howell_model)

male_preds = predict(
  howell_model, 
  howell %>% mutate(male = 1, male = factor(male, levels = c(0, 1)))
)
female_preds = predict(
  howell_model, 
  howell %>% mutate(male = 0, male = factor(male, levels = c(0, 1)))
)
# plot(weight ~ height, howell)
plot(howell$height, male_preds, col = 2, type = "l")
lines(howell$height, female_preds, col = 3)
```


### Ejemplo: dummy variables y contrastes
El dataset `iris` (puedes obtenerlo con `data(iris)`) contiene medidas del sépalo
y pétalo de varias especies de iris. Construye un modelo lineal para predecir
la longitud del sépalo únicamente en funciónde la especie. Interpreta los coeficientes
de la regresión.

```{r iris}
data(iris)
iris_model = lm(Sepal.Length ~ Species, iris)
print(coef(iris_model))

plot(Sepal.Length ~ Species, iris)
predictions = predict(iris_model)
points(iris$Species, predictions, col = iris$Species, pch = 15)

plot(iris$Sepal.Length, col = iris$Species,
xlab = "Observation number", ylab = "Sepal Length")
points(predictions, col = iris$Species, cex = 0.7, pch = 15)
```

Al interpretar los coeficientes de la regresión, quizás hayas observado que 
`lm` ha tomado como referencia la especie `setosa`. Esto se puede observar usando
`contrasts`. De hecho, `contrast` se puede modificar para usar como referencia
otro nivel del factor:

### Ejemplo: contrastes
```{r contrastes}
contrasts(iris$Species)
# Usamos versicolor como referencia
contrasts(iris$Species) = contr.treatment(3, 2)
contrasts(iris$Species)
summary(lm(Sepal.Length ~ Species, iris))
```


## T-tests: comparación de dos grupos

## Ejemplo: dependen los datos
¿Depende la altura de los !Kung adultos del sexo del inviduo? Emplea los datos en 
"howell1.csv".

```{r kung_sex}
adult_howell = filter(howell, age >= 18)
height_model = lm(height ~ male, data = adult_howell)
summary(height_model)
```

### Ejercicio: histogramas 
Apoya tus conclusiones dibujando el histograma de las alturas por sexo

```{r}
ggplot(adult_howell, aes(x = height, fill=male)) + geom_density(alpha=0.2)
```

### Ejercicio: evaluación del modelo
¿Cumple el modelo las asunciones de la regresión lineal?
```{r}
hist(resid(height_model))
```

Lo cierto es que, aunque correcto, nuestra aproximación no es la habitual a la
hora de **comparar la media de dos poblaciones**. Si las poblaciones son normales
(o si podemos invocar el Teorema Central del Límite), podemos hacer uso del 
`t.test`.

### Ejemplo: T-test para comparación de medias
```{r ttest}
male_heights = filter(adult_howell, male == 1)$height
female_heights = filter(adult_howell, male == 0)$height
t.test(male_heights, female_heights)
```

### Ejemplo: T-test de una sola cola 
¿Podemos concluir que los hombres son más altos que las mujeres?

```{r one_sided_ttest}
t.test(male_heights, female_heights, alternative="greater")
```

### Ejercicio: T-test apareado
John M. Morton et al. [^3] examinaron la función de la vesı́cula biliar antes y
después de la fundoplicatura, una cirugı́a para detener el reflujo. Los autores
midieron la funcionalidad de la vesı́cula biliar calculando la fracción de eyección
de la vesı́cula biliar (GBEF) antes y después de la fundoplicatura. El objetivo de
la fundoplicatura es aumentar la GBEF, que se mide como un porcentaje. ¿Hay
evidencia para concluir que la fundoplicatura aumenta el funcionamiento de la
GBEF? Datos en "gbef_long.csv" (o "gbef.csv", para un reto).

```{r gbef}
# df = read.table("data/gbef_long.csv", header = TRUE)
df = read.table("data/gbef.csv")
df
df = 
  df %>% 
  pivot_longer(-(V1:V2), names_to="junk",  values_to = "gbef") %>% 
  select(-V2, -junk) %>%
  rename(class = V1)
df_sp = split(df, df$class)
t.test(df_sp$Postop$gbef, df_sp$Preop$gbef, paired = TRUE, alternative = "greater")
```

### Ejercicio: evaluación del modelo de datos apareados
```{r paired_hist}
d = df_sp$Postop$gbef - df_sp$Preop$gbef
hist(d)
```

## ANOVA: comparación de medias para múltiples grupos


### Ejemplo: One-way ANOVA
Veinticuatro animales fueron asignados aleatoriamente a cuatro dietas diferentes
y se tomaron muestras de sangre en un orden aleatorio. Se midió el tiempo de 
coagulación de la sangre. Datos en "coagulation.csv". ¿Influye la dieta en 
el tiempo de coagulación?


```{r coagulation}
library("car")
coagulation = read.csv("data/coagulation.csv")
options(contrasts = c("contr.sum", "contr.poly")) # for type 3 contrast
coagulation_lm = lm(coag ~ diet, data = coagulation)
coagulation_aov = Anova(coagulation_lm, type = 3)
print(coagulation_aov)
```


```{r coagulation_plot}
print(ggplot(coagulation, aes(x = diet, y = coag, fill = diet)) +
        geom_boxplot() + coord_flip())
```


En general, ANOVA asume:

* Las observaciones son independientes dentro de los grupos y entre los grupos.
* Los datos dentro de cada grupo son normales.
* La variabilidad dentro de cada grupo es aproximadamente igual a la  
variabilidad en los otros grupos. 

```{r}
plot(coagulation_lm, which = c(1, 2), ask=FALSE)
```


```{r}
pairwise.t.test(coagulation$coag, coagulation$diet, p.adj = "bonf")
pairwise.t.test(coagulation$coag, coagulation$diet, p.adj = "BH")  # Benjamini–Hochberg
```

```{r}
library("agricolae")
HSD.test(coagulation_lm, "diet", group=TRUE, console=TRUE)
```

<!-- https://digitalcommons.wayne.edu/cgi/viewcontent.cgi?article=2088&context=jmasm -->
<!-- https://stats.stackexchange.com/questions/2962/omega-squared-for-measure-of-effect-in-r -->
```{r}
library("multcomp") #glht
data("anxiety", package = "datarium")
anxiety <- anxiety %>%
  dplyr::select(id, group, t1, t3) %>%
  rename(pretest = t1, posttest = t3)
anxiety[14, "posttest"] <- 19
```
```{r}
anxiety_lm = lm(posttest ~ pretest + group, anxiety)
Anova(anxiety_lm, type=3)
# we want to test differences between the adjusted means, we can use only
# the glht() function; the pairwise.t.test() function will not test the adjusted means. As such,
# we are limited to using Tukey or Dunnett’s post hoc tests.
postHocs<-glht(anxiety_lm, linfct = mcp(group = "Tukey"))
summary(postHocs)
confint(postHocs)
```


# TODO: ANCOVA

Los diseño de **ANOVA factoriales (factorial = más de un factor)** permiten el efecto
individual y conjunto de uno o más factores. Podemos distinguir varios tipos de
análisis factoriales...

* ... Diseños independientes, 
* Diseños con medidas repetidas, 
* Diseños mixtos.


## ANOVA factorial independiente
## Ejemplo: Sin interacción entre los factores principales
Estudiamos el efecto de tres drogas sobre el tiempo de reacción (una de ellas placebo)
teniendo en cuenta además el sexo de los pacientes que toman el medicamento. Supongamos que 
el efecto de las drogas y edad se mide  en términos de reducción del tiempo de 
reacción a algún estímulo y que se obtienen los resultados del fichero
"drugs_1.csv". Visualiza el efecto de las drogas y sexo en los tiempos de reacción
y propón un modelo.

#TODO: remove
```{r GEN1}
drugs_df <- data.frame(drug=rep(c("Placebo", "A", "B"), 10), sex=rep(c("Male", "Female"),15))
drugs_df$response_time = NA
drugs_df[drugs_df$drug == "Placebo", "response_time"] = 5 + rnorm(10, sd=1) 
drugs_df[drugs_df$drug == "A", "response_time"] = 15 + rnorm(10, sd=1) 
drugs_df[drugs_df$drug == "B", "response_time"] = 25 + rnorm(10, sd=1) 
drugs_df[drugs_df$sex == "Female", "response_time"] =  drugs_df[drugs_df$sex == "Female", "response_time"] + rnorm(15, 4, sd=0.1)
write.csv(drugs_df, "data/drugs_1.csv", row.names = FALSE, )
```

```{r drugs_1}
drugs_df_1 = 
  read.csv("data/drugs_1.csv") %>%
  mutate(drug = factor(drug), sex = factor(sex))

# interaction.plot(drugs_df$sex, drugs_df$drug, response = drugs_df$response_time)
ggplot(drugs_df_1, aes(x=sex, y=response_time, col=drug)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=drug))
```

```{r drugs_1_model}
drugs_model_1 = lm(response_time ~ sex + drug, data = drugs_df_1)
drugs_df_1$predictions = predict(drugs_model_1)

ggplot(drugs_df_1, aes(x=sex, y=predictions, col=drug)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=drug))
```


# TODO: remove
```{r GEN2}
drugs_df <- data.frame(drug=rep(c("Placebo", "A", "B"), 10), sex=rep(c("Male", "Female"),15))
drugs_df$response_time = NA
drugs_df[drugs_df$drug == "Placebo", "response_time"] = 10 + rnorm(10, sd=1) 
drugs_df[drugs_df$drug == "A", "response_time"] = 20 + rnorm(10, sd=1) 
drugs_df[drugs_df$drug == "B", "response_time"] = 30 + rnorm(10, sd=1) 
drugs_df[drugs_df$sex == "Female", "response_time"] =  drugs_df[drugs_df$sex == "Female", "response_time"] + rnorm(15, 4, sd=0.1)
drugs_df[drugs_df$sex == "Male" & drugs_df$drug == "A", "response_time"] = (
  drugs_df[drugs_df$sex == "Male" & drugs_df$drug == "A", "response_time"] + rnorm(5, 20, sd=1)
)
write.csv(drugs_df, "data/drugs_2.csv", row.names = FALSE, )
```


```{r drugs_2}
drugs_df_2 = 
  read.csv("data/drugs_2.csv") %>%
  mutate(drug = factor(drug), sex = factor(sex))

# interaction.plot(drugs_df$sex, drugs_df$drug, response = drugs_df$response_time)
ggplot(drugs_df_2, aes(x=sex, y=response_time, col=drug)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=drug))
```


```{r drugs_2_model}
drugs_model_2 = lm(response_time ~ sex + drug, data = drugs_df_2)
drugs_df_2$predictions = predict(drugs_model_2)

ggplot(drugs_df_2, aes(x=sex, y=predictions, col=drug)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=drug))
```

```{r drugs_2_model_interactions}
drugs_model_2 = lm(response_time ~ sex * drug, data = drugs_df_2) 
# o de forma equivalente
#drugs_model_2 = lm(response_time ~ sex + drug + sex:drug, data = drugs_df_2)
drugs_df_2$predictions = predict(drugs_model_2)

ggplot(drugs_df_2, aes(x=sex, y=predictions, col=drug)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=drug))
```

1. Enter data: you’ve probably gathered this much by now.
2. Explore your data: as always, we’ll begin by graphing the data and computing descrip-
tive statistics. You should check distributional assumptions and use Levene’s test to
check for homogeneity of variance (see Chapter 5).
3. Construct or choose contrasts: you need to decide what contrasts to do and to specify
them appropriately for all of the independent variables in your analysis. If you want
to use Type III sums of squares, these contrasts must be orthogonal.
4. Compute the ANOVA: you can then run the main analysis of variance. Depending on
what you found in the previous step, you might need to run a robust version of the
test.
5. Compute contrasts or post hoc tests: having conducted the main ANOVA, you can
follow it up with post hoc tests or look at the results of your contrasts. Again, the
exact methods you choose will depend upon what you unearth in step 2.



# Ejemplo: Contrastes
```{r}
contrasts(drugs_df_1$drug)
contrasts(drugs_df_1$drug)

contrasts(drugs_df_1$drug) = cbind(c(1, 1, -2), c(-1, 1, 0))
contrasts(drugs_df_1$drug)
```

# Ejercicio: contrastes
```{r}
contrasts(drugs_df_2$drug)
contrasts(drugs_df_2$drug)

contrasts(drugs_df_2$drug) = cbind(c(1, 1, -2), c(-1, 1, 0))
contrasts(drugs_df_2$drug)
```


#Ejercicio: interpretación de los coeficientes ANOVA
Usa ANOVA e interpreta los resultados para los models `drugs_model_1` y `drugs_model_2`.

```{r drugs_interpretation}

drugs_model_1 = lm(response_time ~ sex + drug, data = drugs_df_1)
drugs_model_2 = lm(response_time ~ sex * drug, data = drugs_df_2)

print(Anova(drugs_model_1, type = 3))
print(Anova(drugs_model_2, type = 3))


# Ver contrastes
summary.lm(drugs_model_1)
summary.lm(drugs_model_2)
```
sex1
drug1
drug2
sex1:drug1: El efecto drug1 es diferente en hombres y mujeres? El efecto de placebo Vs drogas es comparable en hombres y mujeres?
sex1:drug2: El efecto drug2 es diferente en hombres y mujeres? El efecto droga A Vs droga B es comparable en hombres y mujeres?
```{r}
contraste_1 = drugs_df_2 %>% mutate(drug = fct_recode(drug, 'Drug' = 'A', 'Drug' = 'B'))
contraste_2 = drugs_df_2 %>% filter(drug != "Placebo") %>% mutate(drug = fct_drop(drug)) 

ggplot(contraste_1, aes(x=sex, y=response_time, col=drug)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=drug))

ggplot(contraste_2, aes(x=sex, y=response_time, col=drug)) + 
  stat_summary() + 
  stat_summary(geom='line', aes(group=drug))
```

No se deben interpretar los efectos principales si la interacción es significativa.


# Posthoc
```{r}
pairwise.t.test(drugs_df_1$response_time, drugs_df_1$drug, p.adjust.method = "bonferroni")
postHocs<-glht(drugs_model_1, linfct = mcp(drug = "Tukey"))
summary(postHocs)
confint(postHocs)
```

#Exercise: Posthoc in drugs_model_2
NO INTERPRETES LOS EFECTOS PRINCIPALES SI TIENES INTERACCION.



## ANOVA factorial con medidas repetidas

F-test in ANOVA depends upon the assumption that scores in
different conditions are independent (see section 10.3). When repeated measures are used
this assumption is violated. 

 The relationship between scores in different treatment conditions
means that an additional assumption has to be made and, put simplistically, we assume
that the relationship between pairs of experimental conditions is similar (i.e., the level of
dependence between experimental conditions is roughly equal). This assumption is called
the assumption of sphericity

Sphericity refers to the
equality of variances of the differences between treatment levels.


Sphericity can be assessed using a test known as Mauchly’s test, which tests the hypothesis
that the variances of the differences between conditions are equal. 

 What do you do if you violate sphericity?
  There are three commonly used
sphericity is violated?
corrections based upon the estimates of sphericity advocated by Greenhouse
and Geisser (1959) and Huynh and Feldt (1976)


Como-> lme or ezANOVA



1. Enter data: which turns out not to be as straightforward as you might think.
2. Explore your data: you know the routine by now – graphs, descriptive statistics and
maybe even a bit of sphericity checking if you’re not going to use lme().
Construct or choose contrasts: you need to decide what contrasts to do and to specify
them appropriately for all of the independent variables in your analysis.
Compute the ANOVA/multilevel model: you can then run the main analysis. Depending
on what you found in the previous step, you might need to run a robust test.
Compute contrasts or post hoc tests: having conducted the main analysis you can fol-
low it up with post hoc tests or look at the results of your contrasts. Again, the exact
methods you choose will depend upon what you unearth in step 2.



## Ejercicio
There is evidence from advertising research that attitudes towards stimuli can be changed
using positive imagery (e.g., Stuart, Shimp, & Engle, 1987). As part of an initiative to stop
binge drinking in teenagers, the government funded some scientists to look at whether neg-
ative imagery could be used to make teenagers’ attitudes towards alcohol more negative.
The scientists designed a study to address this issue by comparing the effects of negative
imagery against positive and neutral imagery for different types of drinks. Table 13.4 illus-
trates the experimental design and contains the data for this example (each row represents
a single participant).
Participants viewed a total of nine mock adverts over three sessions. In one session, they
saw three adverts: (1) a brand of beer (Brain Death) presented with a negative image (a
dead body with the slogan ‘drinking Brain Death makes your liver explode’); (2) a brand
of wine (Dangleberry) presented in the context of a positive image (a sexy naked man or
woman – depending on the participant’s preference – and the slogan ‘drinking Dangleberry
wine makes you irresistible’); and (3) a brand of water (Puritan) presented alongside a neu-
tral image (a person watching television accompanied by the slogan ‘drinking Puritan water
makes you behave completely normally’). In a second session (a week later), the participants
saw the same three brands, but this time Brain Death was accompanied by the positive imag-
ery, Dangleberry by the neutral image and Puritan by the negative. In a third session, the
participants saw Brain Death accompanied by the neutral image, Dangleberry by the nega-
tive image and Puritan by the positive. After each advert participants were asked to rate the
drinks on a scale ranging from −100 (dislike very much) through 0 (neutral) to 100 (like very
much). The order of adverts was randomized, as was the order in which people participated
in the three sessions. This design is quite complex. There are two independent variables:
the type of drink (beer, wine or water) and the type of imagery used (positive, negative or
neutral). These two variables completely cross over, producing nine experimental conditions.

```{r tidying_data}
attitude_df = read.delim("data/attitude.dat", header = TRUE)

attitude_df_long = 
  attitude_df %>% 
  pivot_longer(beer_pos:water_neu, names_to = 'name', values_to = 'attitude') %>% 
  separate(name, into=c('drink', 'imagery'), sep = '_') %>% 
  mutate_if(is.character, as.factor)

write.csv(attitude_df_long, 'data/attitude_long.dat', row.names = FALSE)
```
```{r}
library('ez')
attitude_df_long = read.csv("data/attitude_long.dat", stringsAsFactors = TRUE) %>% as_tibble
attitude_df_long


ggplot(attitude_df_long, aes(x=drink, y=attitude, fill=imagery)) + 
  geom_boxplot()


#### TODO: creo que ezANOVA pasa de los contrastes
contrasts(attitude_df_long$drink)
AlcoholvsWater = c(1, -2, 1)
BeervsWine = c(-1, 0, 1)
contrasts(attitude_df_long$imagery)
NegativevsOther = c(-2, 1, 1)
PositivevsNeutral = c(0, -1, 1)


contrasts(attitude_df_long$drink) = cbind(AlcoholvsWater, BeervsWine)
contrasts(attitude_df_long$drink)

contrasts(attitude_df_long$imagery) = cbind(NegativevsOther, PositivevsNeutral)
contrasts(attitude_df_long$imagery)

library('nlme')

attitudeModel = lme(
  attitude ~ drink * imagery, 
  random = ~1|participant,
  data=attitude_df_long,
  method = "ML"
)

summary(attitudeModel)

postHocs<-glht(attitudeModel, linfct = mcp(drink = "Tukey"))
summary(postHocs)
confint(postHocs)

# X <- model.matrix(~ drink * imagery, data = attitude_df_long)
# glht(attitudeModel, linfct = X)

# emms1 <- emmeans(attitudeModel)
# con1 <- contrast(emms1, interaction = "pairwise")
# pairs(con1, by = NULL)


# If you need more comparisons, you could run post hoc tests (as explained earlier in the chapter)

# #using ezAnova
# 
attitudeModel = ezANOVA(
  data = attitude_df_long,
  dv = .(attitude),  # dv: dependent variable
  wid = .(participant), #
  within = .(drink, imagery),  # sin c() !!:
  type = 3,
  detailed = TRUE
)
# options(digits = 3)
print(attitudeModel)
# print(attitudeModel$ANOVA$ges) # generalized eta-squared
# 
# library('emmeans')
# emm <- emmeans(attitudeModel$aov,  ~ drink * imagery)
# 
# 
# attitude_df_groups = 
#   attitude_df_long %>% 
#   unite(group, all_of(c('drink', 'imagery')))
# 
# contrast(
#   emm, 
#   list(c1 = c(1, -1, 0, 0, 0, 0), # reproduces first pairwise comparison
#        # emmean of row 1 - (emmean of row 1 + emmean of row 2) / 2; see EMMs table
#        # 381.5546 - (379.9286 + 381.6363) / 2
#        c2 = c(1, -0.5, -0.5, 0, 0, 0))
#  )
# 
# pairwise.t.test(attitude_df_groups$attitude, attitude_df_groups$group, paired = TRUE, p.adjust.method = "bonferroni")
# pairs(emm, adjust = "Holm")

```


##
Enter data: which is about as awkward as it was for repeated-measures designs.
Explore your data: as with repeated-measures designs, look at graphs, descriptive
statistics and check sphericity if you’re using ANOVA (boo, hiss) rather than a mul-
tilevel model (hooray!).
Construct or choose contrasts: you need to decide what contrasts to do and to specify
them appropriately for all of the independent variables in your analysis.
Compute the main model: you can then run the main analysis. Depending on what
you found in the previous step, you might need to run a robust version of the test.
Compute contrasts or post hoc tests: having conducted the main analysis, you can
follow it up with post hoc tests or look


# Example: Split-plot 
Las unidades experimentales se organizaron en seis bloques, cada uno con tres parcelas completas subdivididas en cuatro subparcelas. Las variedades de avena se asignaron aleatoriamente a las parcelas enteras y las concentraciones de nitrógeno a las subparcelas. Se usaron las cuatro concentraciones de nitrógeno en cada parcela completa.

![](https://kwstat.github.io/desplot/reference/figures/yates_oats_design.png?raw=true)

```{r}
Oats = Oats %>% mutate(nitro = ordered(nitro))
lme(yield ~ nitro + Variety, random =~ 1 | Block/Variety, data = Oats) %>% 
  summary
```

